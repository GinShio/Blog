[{"categories":["Erlang⁄Elixir"],"content":"GinShio | Elixir学习笔记 (001)","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"好久没学习，随便写点东西，一直想学FP来着，不过之前 Haskell 整的有点难受，好难啊不太会，下次静下心来好好学一学吧，不过先试试 Erlang / Elixir ，听说也很难？ 至于原因，莫名喜欢 Erlang，不知道为什么哈哈哈哈，得知有 Elixir 这个披着 Ruby 皮、用着 Beam 的 Lisp 觉得还不错？毕竟 Lisp 大法好！！ (虽然我不会 lisp) 不过 Elixir 名字好听 Logo 也好看 好了，前置吐槽就这么多吧，希望可以静下心好好学学 Elixir，呃，我也不知道可不可以啦，但是如果对 Elixir 感兴趣的话可以在 Elixir School 尝试学习一下，我也才开始从这里开始学习 ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:0:0","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"基本类型 整数类型：在 Erlang 和 Elixir 中，整数类型都是高精度类型，不区分类型所占的字节，有点类似 Python 中的整数 Elixir 支持 二(0b)、八(0o)、十、十六(0x)进制的整数字面量，使用起来十分方便 255 # 十进制整数 255 0b10001000 # 二进制整数 136 0o7654321 # 八进制整数 2054353 0xFFFF # 十六进制整数 65535 浮点类型：嗯，它是 IEEE 754，好了就这样吧，介绍完了 布尔类型：true 和 false，不过有一点需要注意，在 Elixir 中除了 false 和 nil 之外的所有值都为 true 原子类型：名字和代表的值相同的常量，有点像 Ruby 和 Lisp 中的 Symbol。BTW 布尔值 true / false 实际对应的是原子 :true 和 :false :foo # 符号，名为 :foo :foo == :bar # false is_atom(true) # true is_boolean(:false) # true true == :true # true 大写字母开始的别名也是原子，模块名 (module) 也是原子，当然也可以使用原子直接引用 Erlang 标准库的模块 is_atom(MyAtom) # true is_atom(MyApp.MyModule) # true 字符串：这是一个 UTF-8 编码的字符串，用双引号包住，并且支持换行与转义字符 \"Hello\" # \"Hello\" \"这是一个\\nString\" #这是一个\\nString 当然要讲讲字符串的简单操作了，插值可以将变量插入到字符串中，这个操作有点类似 Ruby 和 Shell 中的操作；字符串拼接操作，可以将两个字符串拼接在一起 name = \"GinShio\" \"Hello #{name}\" # \"Hello GinShio\" \"Hello\" \u003c\u003e \" \" \u003c\u003e name # \"Hello GinShio\" ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:1:0","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"基本操作 ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:2:0","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"算术运算 Elixir 支持基本的 加 (+) 、 减 (-) 、 乘 (*) 、 除 (/)，还有 div 和 mod 两个函数用于整数的除法和取模运算 2 + 3 # 5 6 - 1 # 5 2 * 3 # 6 9 / 3 # 3.0 9 / 2 # 4.5 div(9, 2) # 4 rem(9, 2) # 1 ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:2:1","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"逻辑运算 Elixir 支持逻辑运算，和其他语言差不多的 和(\u0026\u0026) 、 或(||) 、 非(!) -20 || true # -20 false || 42 # 42 nil || true # true 42 \u0026\u0026 true # true 42 \u0026\u0026 false # false 42 \u0026\u0026 nil # nil true \u0026\u0026 false # false !42 # false !false # true 当然还有三个操作符 and 、 or 和 not ，不过这些操作符的地一个参数必须是布尔类型 true and 42 # 42 # 42 and true # (BadBooleanError) expected a boolean on left-side of \"and\" not true # false true and nil # nil # nil and true # (BadBooleanError) expected a boolean on left-side of \"and\" ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:2:2","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"关系运算 常见的关系运算 == 、 != 、 \u003c= 、 \u003c 、 \u003e= 和 \u003e ，这与其他语言中的关系运算符相似 1 \u003e 2 # false 1 != 2 # true 2 == 2 # true 2 \u003c= 3 # true Elixir 还提供了两个关系运算符 === 和 !== ，它们类似于 JS 中的严格比较 2 == 2.0 # true 3 == 3.0000000000000000000000001 # true 2 === 2.0 # false 2 === 2 # true 3 === 3.0000000000000000000000001 # false Elixir 中有一个很重要的特性，任意类型之间都可以比较，因为类型都有一个优先级，支持它们之间互相比较 技巧 number \u003c atom \u003c reference \u003c function \u003c port \u003c pid \u003c tuple \u003c map \u003c list \u003c bitstring 3 \u003c :foo # true {:hello, :world} \u003e [1, 2, 3] # false 9 \u003e [1, 2, 3] # false :bar \u003c [1, 2, 3] # true ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:2:3","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"集合 ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:3:0","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"列表 (List) 列表是简单的集合，可以包含不同的数据类型，并且可以包含相同的值，内部使用 链表 实现，头插相较于尾插更快，获取长度也是 O(n) 的 头插使用 | (cons) 进行操作，可以将元素插入到列表的头部，而拼接操作 ++ 可以将两个列表拼接成一个，而减法操作 -- 是基于严格比较的依照顺序的删除元素 [3.14, :pie, \"Apple\"] # [3.14, :pie, \"Apple\"] [\"π\" | [3.14, :pie]] # [\"π\", 3.14, :pie] [[:foo, \"hello\"] | [\"bar\", :world]] # [[:foo, \"hello\"], \"bar\", :world] [3.14, :pie] ++ [\"Cherry\"] # [3.14, :pie, \"Cherry\"] [1,2,2,3,2,3] -- [1,2,3,2] # [2, 3] [1,2,2,3,2,3] -- [1,2,2,3,3] # [2] [2] -- [2.0] # [2] [2.0] -- [2.0] # [] 列表可以选取 头 (head) 和 尾 (tail)，头是列表的第一个元素，尾是除去第一个元素剩下的列表，也可以和 cons 结合起来获取列表的头部与尾部 hd [3.14, :pie, \"Apple\"] # 3.14 tl [3.14, :pie, \"Apple\"] # [:pie, \"Apple\"] [head | tail] = [3.14, :pie, \"Apple\"] # head = 3.14 # tail = [:pie, \"Apple\"] ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:3:1","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"元组 (Tuple) 元组与列表类似，不过元组使用的是连续内存实现，获取元组的长度很快，但修改很麻烦 (新的元组必须重新在内存中拷贝一份) 元组相较于列表没有那么多操作，元组更倾向于做一个不可变的数据类型，我们常常把二元组称为 pair ，三元组称为 triple ，而其他长度为n的元组称其为 N 元组 (n-tuple)，这个概念在其他语言中也很常见 {3.14, :pie, \"Apple\"} # {3.14, :pie, \"Apple\"} {:foo, \"bar\"} # pair {5, 3.14, :test} # triple ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:3:2","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"关键字列表 (Keyword List) keywords 是一种特殊的列表，列表的元素是 pair，且 pair 的第一个元素必须是原子，其他行为与列表完全一致，不过 keywords 的语法可以不用写 pair 那么复杂，而是简便的 key: value 形式即可 keywords 有一些特殊的特性 键是 原子的 键是 有序的 ，即定义后顺序不会改变 键 不必唯一 [foo: \"bar\", hello: \"world\", pi: 3.14] # [foo: \"bar\", hello: \"world\", pi: 3.14] [{:foo, \"bar\"}, {:hello, \"world\"}, {:pi, 3.14}] # [foo: \"bar\", hello: \"world\", pi: 3.14] keywords = [foo: \"bar\", foo: \"baz\", hello: \"world\"] keywords[:foo] # \"bar\" ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:3:3","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"映射 (Map) 映射也是键值对结构，与 keywords 类似，可以任意类型的数据为键，数据并不严格排序，但是键不能重复，重复的键会覆盖已有的键值对 map 的语法相对麻烦些，以 key =\u003e value 形式书写，好消息是如果键全是原子那么可以与 keywords 的语法类似。map可以像C++一样可以使用 operator[] 读取值，也可以使用 operator. 来读取值 (只可以用于读取原子键) map1 = %{:foo =\u003e \"bar\", \"hello\" =\u003e :world} %{foo: \"bar\", hello: \"world\"} == %{:foo =\u003e \"bar\", :hello =\u003e \"world\"} # true map2 = %{foo: \"bar\", hello: \"world\"} map1[\"hello\"] # :world # map1.hello # (KeyError) key :hello not found map1.foo # \"bar\" map2[:foo] # \"bar\" map2.hello # \"world\" map 提供了 operator| 来更新一个键值对，但仅限于已存在的键值对，如果要添加一个新的键值对则需要用到 put 方法，当然 put 也可以用于更新 map3 = %{foo: \"bar\", hello: \"world\"} %{map3 | foo: \"baz\"} # %{foo: \"baz\", hello: \"world\"} # %{map3 | a: \"b\"} # (KeyError) key :a not found Map.put(map3, :a, \"b\") # %{a: \"b\", foo: \"bar\", hello: \"world\"} ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:3:4","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"语句 小小的吐槽下，本身想把模式匹配放在控制语句之后，毕竟控制语句如果学过其他热门语言肯定是认识的，不过看到 case 时，它依赖模式匹配，好吧…那就先记模式匹配的笔记，好了，开始吧 ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:4:0","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"模式匹配 模式匹配经常被用于函数、case等地方，用的还是蛮多的，且方便，模式匹配中必须穷尽示例用以匹配，如果默认值需要使用变量 _ 来接收默认情况，类似 C 语言的 switch 语句中的 default 匹配 我们一直没有将 = 这个其他语言中的赋值符号，在 Erlang/Elixir 中这不止是赋值，准确的将，这是 匹配 ，接下来我们写一点 Erlang 的语句来体验一下匹配，不要害怕，这和我们已经学会的 Elixir 几乎一样，如果要一直学习 Elixir 的话 Erlang 是逃不掉的，Lisp 不知道能逃掉不 Var = 10. % 将 var 与 10 匹配 % Var = 5. % exception error: no match of right hand side value 5 10 = Var. % 10 % 5 = Var. % exception error: no match of right hand side value 10 Erlang 中可以看到变量 Var 与 10 匹配，匹配之后便不能与 5 匹配了，与 5 匹配将出现错误，这与 Elixir 中是类似的 list = [1, 2, 3] # [1, 2, 3] [1, 2, 3] = list # [1, 2, 3] # [] = list # (MatchError) no match of right hand side value: [1, 2, 3] 现在想想之前学习 list 时使用的 operator| ，取 head 和 tail 时其实也是匹配，匹配时对于不关注的变量可以使用变量 _ 替代 [head | tail] = [1, 2, 3] # haed = 1, tail = [2, 3] [head | _] = [1, 2, 3] # head = 1 {:ok, value} = {:ok, \"Successful\"} # value = \"Successful\" # {:ok, value} = {:error, \"Error\"} # (MatchError) no match of right hand side value Pin Elixir 在匹配时，匹配操作会同时做赋值操作，但 Erlang 中不会，我们可以使用 Pin 操作符 ^ 来保持与 Erlang 中行为的一致 var = 10 # OK, var = 10 ^var = 5 # NO, (MatchError) no match of right hand side value var = 5 # OK, var = 5 5 = var # OK, match pin 也可以被用于常见的数据结构中 x = 1 {x, ^x} = {2, 1} # x = 2 # {^x, x} = {2, 1} # (MatchError) no match of right hand side value key = \"hello\" %{^key =\u003e value} = %{\"hello\" =\u003e \"world\"} # value = \"world\" # %{^key =\u003e value} = %{:hello =\u003e \"world\"} # (MatchError) no match of right hand side value ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:4:1","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"控制语句 控制语句主要分为3种 if / unless ： if 与 unless 是条件语句，与其他语言的 if 语句类似，if 与 unless 语义相反，在 Elixir 中都是宏定义 if String.valid?(\"Hello\") do \"Valid String\" else \"Invalid String\" end # \"Valid String\" unless String.valid?(\"World\") do \"Invalid String\" else \"Valid String\" end # \"Valid String\" case ： case 是一种匹配语句，基于模式匹配 case {:ok, \"Hello World\"} do {:ok, result} -\u003e result {:error} -\u003e \"Uh oh!\" _ -\u003e \"Catch all\" end # Hello World cond ：当我们需要匹配条件而不是值的时候，可以使用 cond，它的语法很像 case，按顺序匹配每一个条件，必须有一个为真的表达式，所以一般在结尾设置 true 匹配，有些像 Haskell 中的 守卫 表达式 cond do 2 + 2 == 5 -\u003e \"2+2==5\" 2 * 2 == 8 -\u003e \"2*2==8\" true -\u003e \"All Error\" end # \"All Error\" with ： with 类似于 case 语句，适用于嵌套的 case 语句，按照顺序一次匹配表达式，当失败时会返回对应的返回值 user = %{first: \"Xin\", last: \"Liu\"} with {:ok, first} \u003c- Map.fetch(user, :first), {:ok, last} \u003c- Map.fetch(user, :last) do last \u003c\u003e \", \" \u003c\u003e first end # \"Liu, Xin\" with {:ok, first} \u003c- Map.fetch(user, :first), {:ok, hello} \u003c- Map.fetch(user, :hello) do hello \u003c\u003e \", \" \u003c\u003e first end # :error with 支持 else 语句，当 with 出现不匹配时，将其返回值在 else 中进行匹配，else 是类似 case 语法的模式匹配，需要穷尽匹配 with {:ok, number} \u003c- Map.fetch(%{a: 1, b: 4}, :a), true \u003c- is_even(number) do IO.puts \"#{number}divided by 2 is #{div(number, 2)}\" :even else :error -\u003e IO.puts(\"We don't have this item in map\") :error _ -\u003e IO.puts(\"It's odd\") :odd end ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:4:2","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"函数 ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:5:0","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"匿名函数 先说说匿名函数吧，lambda 表达式是函数式编程语言的基础， lambda 演算 与 图灵机 堪称计算机程序设计语言的两大支柱，这里我们不学习那么深入，有兴趣嘛那就加油吧，我们简单说说 Elixir 中的 lambda，Elixir 中函数是一等公民，它们可以像变量一样使用与传递，威力十足！ 简单的语法即 fn (params) -\u003e statements ，这便会定义一个匿名函数，这个函数可以赋值给一个对象，或者传递进一个参数中；如果需要使用，则需要 name.(param) 来调用 sum = fn (a, b) -\u003e a + b end sum.(2, 3) # 5 很简单吧，这更像是一个完整的函数定义，还有一种做法是像 Shell 中使用函数参数，即使用参数的顺序来确定形式参数的使用；这就让 lambda 简单多了，当然也更难理解参数的含义了。我们在此简单的说明下， \u0026() 这是一个匿名函数， \u00261 这是这个函数接收的第一个参数，以此类推 sum = \u0026(\u00261 + \u00262) sum.(2, 3) # 5 # sum.(\"String\", 666) # 错误: (ArithmeticError) bad argument in arithmetic expression: \"String\" + 666 # sum.(2, 3, 4) # 错误: (BadArityError) \u0026:erlang.+/2 with arity 2 called with 3 arguments 模式匹配可以用在函数中，我们先来看看匿名函数中的模式匹配，和 case 差不多，不过这是个函数 handle_result = fn {:ok, result} -\u003e IO.puts(\"Handling result...\") {:ok, _} -\u003e IO.puts(\"This would be never run as previous will be matched beforehand.\") {:error} -\u003e IO.puts(\"An error has occurred!\") end ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:5:1","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"命名函数 命名函数一般被定义在模块中，使用关键字 def 定义，如果函数体与头在一行的使用可以使用 do: 来简单的书写 defmodule MyModule do def hello1(name) do \"Hello\" \u003c\u003e \", \" \u003c\u003e name end def hello2(name), do: \"Hello\" \u003c\u003e \". \" \u003c\u003e name end MyModule.hello1(\"GinShio\") # Hello, GinShio MyModule.hello2(\"GinShio\") # Hello. GinShio 函数式语言往往也可以进行函数重载，不过他们一般只按照函数参数的个数进行重载，这在 Elixir 中也适用，在 Elixir 中函数的全程一般是 name/param_num defmodule MyModule do def hello(), do: \"Hello, Everybody\" # hello/0 def hello(name), do: \"Hello\" \u003c\u003e \", \" \u003c\u003e name # hello/1 end MyModule.hello() # \"Hello, Everybody\" MyModule.hello(\"iris\") # \"Hello, iris\" 命名函数当然也可以很好的支持模式匹配，这样我们递归的实现会很简单 defmodule MyLength do def of([]), do: 0 def of([_ | tail]), do: 1 + of(tail) end MyLength.of([]) # 0 MyLength.of([1, 2, 3, 4, 5]) # 5 当然模式匹配与 Map 结合在一起，示例函数 hello/1 展示了只关注指定键的用法，当然我们也可以在关注指定键时接受整个 Map，即用模式匹配来接受 defmodule MyModule do def hello(%{name: person}), do: \"Hello, \" \u003c\u003e person def all_map(%{name: person_name} = person) do IO.puts \"Hello, \" \u003c\u003e person_name IO.inspect person end end MyModule.hello(%{name: \"Fred\", age: 95}) # \"Hello, Fred\" # MyModule.hello(%{age: 95}) # (FunctionClauseError) no function clause matching in MyModule.hello/1 MyModule.all_map(%{name: \"Fred\", age: 95}) # Hello, Fred # %{age: 95, name: \"Fred\"} Private (私有函数)：如果你不希望模块外调用某些函数，你可以使用 defp 来定义私有函数，这样定义的函数只能在模块内使用 defmodule MyFibonacci do def fib(0), do: 0 def fib(1), do: 1 def fib(n), do: fib(1, 1, n) defp fib(ans, pre, 2), do: ans defp fib(ans, pre, n), do: fib(ans + pre, ans, n - 1) end MyFibonacci.fib(10) # 55 MyFibonacci.fib(100) # 354224848179261915075 # MyFibonacci.fib(1, 1, 5) # (UndefinedFunctionError) function MyFibonacci.fib/3 is undefined or private. Pipe |\u003e (管道操作)：没错你没听错，就是 pipe，有没有想起使用 *nix 时使用的管道，Elixir 中的 pipe 与 *nix 中的类似，都是将前一个调用的结果传递给后一个，这就很爽了，我们来对比一下，管道简直是嵌套调用的救星 foo(bar(baz(do_something()))) # Normal do_something() |\u003e baz() |\u003e bar() |\u003e foo() # Pipe 那如果参数数量大于1怎么办，这些问题不大，带上参数就行，从 Pipe 来的参数优先入栈 \"Hello, World\" |\u003e String.split() # [\"Hello,\", \"World\"] \"Hello, World\" |\u003e String.split(\", \") # [\"Hello\", \"World\"] Guard (守卫表达式)：可以被用于 函数 和 case 当中，比方说我们现在有两个签名相同的函数 hello/1 ，我们需要通过 guard 来确定应该调用哪个函数 defmodule MyModule do def hello(names) when is_list(names) do names |\u003e Enum.join(\", \") |\u003e hello() end def hello(names) when is_binary(names) do \"Hello, \" \u003c\u003e names end end MyModule.hello(\"GinShio\") # \"Hello, GinShio\" MyModule.hello([\"GinShio\", \"iris\"]) # \"Hello, GinShio, iris\" 我们试试在 case 中使用 guard，更多用法请查看 Guard clauses case x do 1 -\u003e :one 2 -\u003e :two n when is_integer(n) and n \u003e 2 -\u003e :larger_than_two end Default (默认参数)：我们可以为函数设置一些默认值，使用语法 argument \\\\ value defmodule MyModule do def hello(name, language_code \\\\ \"en\"), do: phrase(language_code) \u003c\u003e name defp phrase(\"en\"), do: \"Hello, \" defp phrase(\"es\"), do: \"Hola, \" defp phrase(\"zh\"), do: \"你好，\" end MyModule.hello(\"iris\") # \"Hello, iris\" MyModule.hello(\"iris\", \"en\") # \"Hello, iris\" MyModule.hello(\"iris\", \"es\") # \"Hola, iris\" MyModule.hello(\"iris\", \"zh\") # \"你好，iris\" 不过我们在默认参数与守卫表达式一起使用时，往往会出现一些问题，先来看看问题代码 defmodule Greeter do def hello(names, language_code \\\\ \"en\") when is_list(names) do names |\u003e Enum.join(\", \") |\u003e hello() end def hello(names, language_code \\\\ \"en\") when is_binary(names) do phrase(language_code) \u003c\u003e names end defp phrase(\"en\"), do: \"Hello, \" defp phrase(\"es\"), do: \"Hola, \" end # (CompileError): def hello/2 defines defaults multiple times. # Elixir allows defaults to be declared once per definition. Instead of: # def foo(:first_clause, b \\\\ :default) do ... end # def foo(:second_clause, b \\\\ :default) do ... end 有多个函数同时匹配时，默认参数这种模式很容易混淆，它不被 Elixir 喜欢，至于解决方法嘛还是有的，我们需要先声明这个函数，有点像 C++ 使用默认参数的方法 defmodule Greeter do def hello(names, language_code \\\\ \"en\") def hello(names, language_code) when is_list(names) do names |\u003e Enum.join(\", \") |\u003e hello() end def hello(names, language_code) when is_binary(names) do phrase(language_code) \u003c\u003e names end defp phrase(\"en\"), do: \"Hello, \" defp phrase(\"es\"), do: \"Hola, \" end ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:5:2","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"模块 之前函数的时候也简单的见过模块了，Elixir 允许嵌套模块，这样可以轻松定义多层命名空间 defmodule Greeter.Greeting do def morning(name), do: \"Good morning, #{name}\" def evening(name), do: \"Good evening, #{name}\" end Greeter.Greeting.morning(\"iris\") # \"Good morning, iris\" 模块通常还会有一些属性，这些属性通常被用作常量 defmodule Example do @greeting \"Hello\" def greeting(name) do ~s(#{@greeting}, #{name}.) end end Example.greeting(\"iris\") # \"Hello, iris.\" 当然还有一些的属性，用于保留功能，比如 moduledoc 和 doc 作为文档，文档可以用 ExDoc 生成 HTML，而 ExMark 是一个 Markdown 分析器，最终我们可以使用 mix 来生成文档 defmodule Example do @moduledoc \"\"\" This is the Hello module. \"\"\" @moduledoc since: \"1.0.0\" @doc \"\"\" Says hello to the given `name`. Returns `:ok`. ##Examples iex\u003e Example.world(:john) :ok \"\"\" @doc since: \"1.3.0\" def world(name) do IO.puts(\"hello #{name}\") end end ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:6:0","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"结构体 (Struct) 在 Elixir 中结构体 Struct 是 Map 的特殊形式，它的键是预定义的，一般都有默认值，不过有个限制，Struct 只能定义在 Module 中，一般一个模块定义一个结构体 defmodule Example.User do defstruct name: \"GinShio\", roles: [] end default = %Example.User{} # %Example.User{name: \"GinShio\", roles: []} iris = %{default | name: \"iris\"} # %Example.User{name: \"iris\", roles: []} inspect(default) # \"%Example.User{name: \\\"GinShio\\\", roles: []}\" %Example.User{name: \"iris\"} = iris # pattern 可以看到 inspect 展示了 Struct 中的所有字段，如果我们想排除保护字段，可以使用 @derive 注解来实现这一功能 defmodule Example.User do @derive {Inspect, only: [:name]} # 只打印 :only 中的字段 # @derive {Inspect, except: [:roles]} # 排除 :except 中的字段 defstruct name: nil, roles: [] end inspect(default) # \"#Example.User\u003cname: \\\"GinShio\\\", ...\u003e\" ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:6:1","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["Erlang⁄Elixir"],"content":"组合 (Composition) Elixir 以组合的方式为模块添加全新的功能，并且也为我们提供了多种访问其他模块的方式 alias (别名)：通过别名访问其他模块，当别名有冲突时还可以使用 as 来设置别名解决冲突，当然也可以一次指定多个别名 defmodule Example.Source do def hello(name), do: \"Hello, #{name}!\" end defmodule Example.Alias do alias Example.Source def hello(), do: Source.hello(\"FooBar\") end defmodule Example.AliasMulti do alias Example.{Source, Alias} def hello(), do: Source.hello(\"Src\") end defmodule Other.Alias do alias Example.Alias, as: ExAlias def hello(), do: ExAlias.hello() end import (导入)：我们可以从其他模块导入函数，不过这有些污染名称空间 # last([1, 2, 3]) # (CompileError): undefined function last/1 List.last([1, 2, 3]) # 3 import List last([1, 2, 3]) # 3 好消息是，就像之前学习 Struct 时控制 inspect 输出一样， :only 与 :except 是我们控制 import 导出的好帮手 import List, only: [last: 1] # only import `last/1' first([1, 2, 3]) # (CompileError): undefined function first/1 last([1, 2, 3]) # 3 我们如果想导出所有的函数呢，这样太麻烦了吧，好在 Elixir 提供了一种特殊的方法， :functions 和 :macros 分别代表函数和宏，不过不能除外就是了 import List, only: :functions # 导出 List 中的所有函数 import List, only: :macros # 导出 List 中的所有宏 # import List, except: :functions # (CompileError): invalid :except option for import, expected value to be a list literal, got: :functions require (请求)：这是一个只对宏有效的指令，虽然不知道宏是什么，不过只要知道它只 import 模块中的宏而不是函数，目前来说就行了 use (使用)：这是一个修改当前模块的指令，我们在调用 use 时会执行指定模块中所定义的 __using__ 宏进行回调，当然现在不懂没关系，在学习了宏之后再来学习这里吧 (反正我也不懂 defmodule Hello do defmacro __using__(opts) do quote do def hello(name), do: \"Hi, #{name}\" end end end defmodule Example do use Hello end Example.hello(\"GinShio\") # \"Hi, GinShio\" 非常的神奇，当然宏还是可以带参数的，比如下面这个从 Elixir School 抄来的示例 (这个更看不懂了 defmodule Hello do defmacro __using__(opts) do greeting = Keyword.get(opts, :greeting, \"Hi\") quote do def hello(name), do: unquote(greeting) \u003c\u003e \", \" \u003c\u003e name end end end defmodule Example.En do use Hello end defmodule Example.Es do use Hello, greeting: \"Hola\" end Example.En.hello(\"GinShio\") # \"Hi, GinShio\" Example.Es.hello(\"GinShio\") # \"Hola, GinShio\" ","date":"2021-02-16","objectID":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/:6:2","tags":["FP","Elixir","编程语言"],"title":"Elixir学习笔记 001","uri":"/2021/elixir%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_001/"},{"categories":["C++"],"content":"GinShio | Cpp Concurrency in Action (2rd) 第五章读书笔记","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"原子操作 原子操作是一个不可分割的操作，系统的所有线程不会观察到原子操作完成了一半。如果读取对象的加载操作是原子的，那么这个对象的所有修改操作也是原子的。 标准原子类型全部定义于头文件 atomic 中，这些类型的操作都是原子的，但是其内部实现可能使用原子操作或互斥量模拟，所以原子操作可以替代互斥量完成同步操作，但是如果内部使用互斥量实现那么不会有性能提升。 通常标准原子类型不能进行拷贝和赋值，但是可以隐式转化成对应的内置类型，使用 load() 、 exchange() 、 compare_exchange_weak() 和 compare_exchange_strong() ，另外还有 store() 用以原子地赋值。每种函数类型的操作都有一个内存序参数，这个参数可以用来指定存储的顺序。 ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:1:0","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"::std::atomic_flag ::std::atomic_flag 是最简单的原子类型，标准保证其实现是 lock-free 的，这个类型的对象可以在 设置 和 清除 间切换，对象必须被 ATOMIC_FLAG_INIT ，初始化标志位为清除状态。初始化后，对象进可以执行销毁、清除、设置 ::std::atomic_flag f = ATOMIC_FLAG_INIT; // 设置为清除状态 (false) 由于 clear() 清除操作原子地设置标志为 false， test_and_set() 设置操作原子地设置标志为 true 并获得其先前值，所以可以简单地实现一个自旋锁 class spinlock_mutex { private: ::std::atomic_flag flag; public: spinlock_mutex() : flag(ATOMIC_FLAG_INIT) {} void lock() { while (flag.test_and_set(::std::memory_order_acquire)); } void unlock() { flag.clear(::std::memory_order_release); } }; ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:1:1","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"::std::atomic ::std::atomic 不再保证 lock-free ，但相比 ::std::atomic_flag 有了更通用的操作， store() 是一个存储操作， load() 是一个加载操作， exchange() 是一个读-改-写操作。 ::std::atomic\u003cbool\u003e b; bool x = b.load(::std::memory_order_acquire); // 加载操作，x==false b.store(true); // 存储操作，b==true x = b.exchange(false, ::std::memory_order_acq_rel); // 读-改-写操作，b==false，x==true 原子操作中还有一种存储方式：当前值与预期值一致时存储新值，这种操作被称为 compare/exchange (比较/交换) 操作。compare/exchange 是原子类型编程的基础，它比较原子变量的当前值和预期值，两者相等时存储目标值，当两者不相等时预期值会被更新为原子变量中的值。它在C++中以 compare_exchange_weak() 和 compare_exchange_strong() 提供，将当前值与预期值的 对象表示/值表示 逐位比较，且复制是逐位的，比较相等将返回 true，否则返回 false。另外我们可以指定两个内存序，即成功修改原子变量的内存序与失败时可以是不同的，具体的内存序我们之后在学习。 compare_exchange_weak 是 弱CAS ，可能出现伪失败，即当前值与预期值相等时，也可能出现比较失败的行为，为此通常配合循环使用 bool expected = false; extern ::std::atomic\u003cbool\u003e b = false; while (!b.compare_exchange_weak(expected, true) \u0026\u0026 !expected); compare_exchange_strong 是 强CAS ，它保证不会出现伪失败，一般推荐使用强形式 ::std::atomic\u003cint\u003e ai = 3; int tst = 4; ai.compare_exchange_strong(tst, 5); // false, ai = 3, tst = 3 ai.compare_exchange_strong(tst, 5); // true, ai = 5, tst = 3 整数类型、指针类型、浮点类型 (C++20起) 都拥有原子数值计算的能力，并且整数类型还可以原子地按位运算，这些操作可以修改原子变量并返回修改前原子变量的值 int arr[5] = {0}; ::std::atomic\u003cint\u003e ai{5}; ::std::atomic\u003cint*\u003e aip{arr}; // 数值计算 ai += 4; // ai = 9 aip += 2; // aip = arr + 2 ai.fetch_sub(8); // ai = 1 --aip; // aip = arr + 1 // 按位运算 (仅整数类型特化) ai |= 2; // ai = 3 ai.fetch_and(4); // ai = 0 类型中包含 填充位 、 陷阱位 或为 同一值提供多个对象表示 (如浮点数的 NaN) 时推荐弱CAS，因为可能两个对象的值相等但CAS操作失败 struct TestCas { int i; char : 1; }; TestCas a = {65536}; // 假设对象表示 [0,0,1,0,1,0,0,0] ::std::atomic\u003cTestCas\u003e aa{{65536}}; // 假设对象表示 [0,0,1,0,0,0,0,0] aa.compare_exchange_strong(a, {1024}); // 修改失败，对象表示不一致 // C++20开始，修改成功，值表示一致 我们常使用 用户定义类型 (UDT)，原子类型会进行逐位比较或复制操作，所以 UDT 应该是 可平凡复制 的类型。通常 UDT 类型的原子类型会使用锁来完成原子操作，不过好消息是大多数平台对于 UDT 大小如同一个 int 或 void* 时，将使用原子指令实现原子操作 (即无锁操作)，有些平台甚至还支持两倍大小使用原子指令，即 双字比较和交换 (DWCAS) 指令 ::std::cout \u003c\u003c ::std::boolalpha \u003c\u003c aa.is_lock_free() \u003c\u003c ::std::endl; // 可能的输出：true ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:1:2","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"内存布局 内存模型一方面是内存布局，另一方面是并发，并发的基本结构很重要，特别是低层原子操作，因为C++所有的对象都和内存位置有关。一个类是一个有多个子对象组成的对象，我们需要牢记四个原则 每个变量都是对象，包括其成员变量的对象 每个对象至少占有一个内存位置 基本类型都有确定的内存位置 相邻位域是相同内存中的一部分 ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:2:0","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"数据模型 数据模型描述了C等编程语言的基本算术类型的位宽，以下是常见的数据模型 (之后我们以 LP64 为准) 数据模型 short int long long long ptr RunTime LP32 16 16 32 64 32 MSVC (16bit) ILP32 16 32 32 64 32 MSVC (32bit) 和 *nix (32bit) LLP64 16 32 32 64 64 MSVC 和 MinGW LP64 16 32 64 64 64 *nix, Cygwin, z/OS ILP64 16 64 64 64 64 Solaris SILP64 64 64 64 64 64 UNICOS ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:2:1","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"内存对齐 内存对齐主要是为了提高内存的访问效率，也为了更好的移植性。但是这样会改变各个成员在类中的偏移量，类的大小也不再是简单的成员大小相加，幸好其中也有一些规律可循 对象的起始地址能够被其最宽的成员大小整除 成员相对于起始地址的偏移量能够被自身大小整除，否则在前一个成员后面填充字节 类的大小能够被最宽的成员的大小整除，否则在最后填充字节 如果是空类，按照标准该类的对象必须占有一个字节 (除非 空基类优化)，在C中空类的大小是0字节 当指定对齐的时候，类的大小将是指定对齐大小的倍数，如果不足则在最后填充字节 好的，那么我们看一些简单的例子，基本上都可以算出下面各个类占用多少内存，并可以知道在哪里填充内存 struct A {}; // sizeof(A): 1, alignof(A): 1 struct B { short b_a; // 2 bytes int b_b; char b_c; // 3 bytes }; // sizeof(B): 12, , alignof(B): 4 struct C : public A { int c_a; }; // sizeof(C): 4, alignof(C): 4 struct D { A d_a; // 3 bytes int d_b; }; // sizeof(D): 8, alignof(D): 4 我们加入一些数组进来, 数组中的元素当然也会符合内存对齐的规则 struct E { int e_a; char e_b[3]; // 1 byte }; // sizeof(E): 8, alignof(E): 4 struct F { char f_a[3]; // 5 bytes long long f_b; short f_c[3]; // 2 bytes F* f_d; }; // sizeof(F): 32, alignof(F): 8 指定内存对齐的方式时，必须是2的正幂，若指定的对齐方式弱于原生对齐方式，将忽略指定 struct alignas(16) G { char g_a[3]; // 1 byte short g_b; // 10 bytes }; // sizeof(G): 16, alignof(G): 16 struct H : public G { short h_a; // 2 bytes int h_b; // 10 bytes }; // sizeof(H): 32, alignof(H): 16 struct alignas(2) I { // 弱于原生对齐方式(4) C c; }; // sizeof(I): 4, alignof(I): 4 位域只会占有多个二进制位，而不会占有整个字节，不过位域也遵循内存对齐的原则 位域的宽度不能超过底层类型的宽度 多个位域可以共享同一底层类型，当底层类型不够存储位域时，将从下一分配单位开始存储 允许空位域用以占位，则将不使用空位域 大小为零的空位域将强制填充剩下的位，之后的位域将从新的分配单位开始存储 位域是否可以 跨字节 与 打包方式 ，由实现而定 struct J { int j_a :6; int j_b :4; // 与 j_c 共享字节 int j_c :4; // 与 j_b 共享字节 char j_d; // 1 byte }; // sizeof(J): 4, alignof(J): 4 struct K { int k_a :3; int :4; // 与 k_a 共享字节 int k_b :2; // 独占一字节 char k_c; // 1 byte }; // sizeof(K): 4, alignof(K): 4 struct L { int l_a :3; int :0; // 将 int 剩下的部分填充 char l_b :2; char l_c; // 2 bytes }; // sizeof(L): 8, alignof(L): 4 一个内存位置是 一个标量类型 (算术类型、指针类型、枚举类型或 ::std::nullptr_t) 对象 或非零长位域的最大相接序列 C++的各种功能特性，例如引用和虚函数，可能涉及到程序不可访问，但为实现所管理的额外内存位置。 struct S { char a; // 内存位置 #1 int b : 5; // 内存位置 #2 int c : 11, // 内存位置 #2 （延续） : 0, d : 8; // 内存位置 #3 struct { int ee : 8; // 内存位置 #4 } e; } obj; // 对象 'obj' 由 4 个分离的内存位置组成 ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:2:2","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"内存位置与并发 当多个线程访问不同的内存位置时将不会存在任何问题，但是当写入与读取在同一内存位置时将会产生数据竞争，当然也有特例不会引起数据竞争 两个同一内存位置上的操作在 同一线程 上 冲突是 原子操作 一个冲突操作发生 早于 另一个 对象都有在初始化开始阶段确定好修改顺序的，大多数情况下，这个顺序不同于执行中的顺序，但在给定的程序中，所有线程都需要遵守这个顺序。如果对象不是原子类型，必须确保有足够的同步操作，确定线程都遵守了修改顺序。 ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:2:3","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"同步操作和强制排序 ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:3:0","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"相关术语 线程间同步和内存顺序决定表达式的求值和副效应如何在不同的执行线程间排序 同步于 (synchronizes-with)：修改原子对象 M 的求值 A，对于其他线程可见 先序于 (sequenced-before)：在同一线程中求值 A 可以先序于求值 B 携带依赖 (carries dependency)：在同一线程中若下列任一为真，则先序于求值 B 的求值 A 可能也会将依赖带入 B A 的值被用作 B 的运算数，除了 B 是对 ::std::kill_dependency 的调用 A 是内建 \u0026\u0026、||、?: 或 , 运算符的左运算数 A 写入标量对象 M，B 从 M 读取 A 将依赖携带入另一求值 X，而 X 将依赖携带入 B 修改顺序 (modification order)：对任何特定的原子变量的修改，以限定于此一原子变量的单独全序出现，对所有原子操作保证下列四个要求： 写写连贯 ：若修改某原子对象 M 的求值 A 先发于 修改 M 的求值 B，则 A 在 M 的修改顺序中早于 B 出现 读读连贯 ：若某原子对象 M 的值计算 A 先发于 对 M 的值计算 B，且 A 的值来自对 M 的写操作 X，则 B 的值要么是 X 所存储的值，要么是在 M 的修改顺序中后于 X 出现的 M 上的副效应 Y 所存储的值 读写连贯 ：若某原子对象 M 的值计算 A 先发于 修改 M 的求值 B，则 A 的值来自 M 的修改顺序中早于 B 出现的副效应 X 写读连贯 ：若某原子对象 M 上的副效应 X 先发于 M 的值计算 B，则求值 B 应从 X 或从 M 的修改顺序中后随 X 的副效应 Y 取得其值 释放序列 (release sequence)：在原子对象 M 上执行一次释放操作 A 之后，M 的修改顺序的最长连续子序列被称为以 A 为首的释放序列 由执行 A 的同一线程所执行的写操作 (C++20前) 任何线程对 M 的原子的读-改-写操作 依赖先序于 (dependency-ordered before)：在线程间若下列任一为真，则求值 A 依赖先序于求值 B A 在某原子对象 M 上进行释放操作，而不同的线程中 B 在同一原子对象 M 上进行消费操作，而 B 读取 A [所引领的释放序列的任何部分 (C++20 前)] 所写入的值 A 依赖先序于 X 且 X 携带依赖到 B 线程间先行发生 (inter-thread happens-before)：在线程间若下列任一为真，则求值 A 线程间先行发生于求值 B A 同步于 B A 依赖先序于 B A 同步于某求值 X，且 X 先序于 B A 先序于某求值 X，且 X 线程间先行发生于 B A 线程间先行发生于某求值 X，且 X 线程间先行发生于 B 先行发生 (happens-before)：先行发生无关乎线程，若下列任一为真，则求值 A 先发生于求值 B A 先序于 B A 线程间先发生于 B ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:3:1","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"内存顺序 C++ 标准定义了六种原子操作的内存顺序，它们代表了四种种内存模型： 顺序一致性 (Sequentially-consistent ordering)、 获取-释放序 (Acquire-Release ordering)、 消费-释放序 (Consume-Release ordering) 和 自由序 (Relaxed ordering)，以下列出所有内存序并按照一致性要求由弱到强排列 值 释义 memory_order_relaxed 自由序内存模型，没有同步或顺序制约，仅对此操作要求原子性 memory_order_consume 当前线程中依赖于当前加载的该值的读或写不能被重排到此加载前；其他释放同一原子变量的线程对数据依赖变量的写入，为当前线程所可见 memory_order_acquire 当前线程中读或写不能被重排到此加载前；其他释放同一原子变量的线程的所有写入，能为当前线程所见 memory_order_release 当前线程中读或写不能被重排到此存储后；当前线程的所有写入，对其他获取同一原子变量的线程可见，对原子变量的带依赖写入变得对其他消费同一原子对象的线程可见 memory_order_acq_rel 所有释放同一原子变量的线程的写操作在当前线程修改前可见，当前线程改操作对其他获取同一原子变量的线程可见 memory_order_seq_cst 顺序一致性内存模型，原子操作的默认内存序，所有线程以同一顺序观测到所有修改 在不同的原子操作上，可以用到的内存序也有所不同 store (写操作)：memory_order_relaxed，memory_order_release，memory_order_seq_cst load (读操作)：memory_order_relaxed，memory_order_consume，memory_order_acquire，memory_order_seq_cst read-modify-write (读改写操作)：memory_order_relaxed，memory_order_consume，memory_order_acquire，memory_order_release，memory_order_acq_rel，memory_order_seq_cst 自由序 带标签 memory_order_relaxed 的原子操作，它们不会在同时的内存访问间强加顺序，它们只保证原子性和修改顺序一致性，典型应用场景为 计数器自增 // x = {0}, y = {0} // 线程 1 r1 = y.load(::std::memory_order_relaxed); // A x.store(r1, ::std::memory_order_relaxed); // B // 线程 2 r2 = x.load(::std::memory_order_relaxed); // C y.store(42, ::std::memory_order_relaxed); // D assert(r1 != 42 || r2 != 42); // E A 先序于 B，C 先序于 D，但 D 在 y 上的副效应可能对 A 可见，同时 B 在 x 上的副效应可能对 C 可见，所以允许 E 断言失败。 另外自由序中，当前线程可能看到别的线程的更新，但是更新频率不一定是均匀的，但其值一定是递增的。详细例子可以查看 C++ Concurrency in Action (2rd) 中电话计数员的例子。 消费-释放序 若线程 A 中的原子存储带标签 memory_order_release 而线程 B 中来自同一对象的读取存储值的原子加载带标签 memory_order_consume，则线程 A 视角中先发生于原子存储的所有内存写入，会在线程 B 中该加载操作所携带依赖进入的操作中变成可见副效应，即一旦完成原子加载，则保证线程 B 中使用从该加载获得的值的运算符和函数能见到线程 A 写入内存的内容。同步仅在释放和消费同一原子对象的线程间建立，其他线程能见到与被同步线程的一者或两者相异的内存访问顺序。 此顺序的典型使用情景，涉及对 很少被写入 的数据结构的同时时读取，和 有指针中介发布 的发布者-订阅者情形，即当生产者发布消费者能通过其访问信息的指针之时：无需令生产者写入内存的所有其他内容对消费者可见。这种场景的例子之一是 rcu 解引用。 ::std::atomic\u003c::std::string*\u003e ptr; int data; void producer() { ::std::string* p = new ::std::string(\"Hello\"); data = 42; ptr.store(p, ::std::memory_order_release); } void consumer() { ::std::string* p2; while (!(p2 = ptr.load(::std::memory_order_consume))); assert(*p2 == \"Hello\"); // 断言成功 (*p2 从 ptr 携带依赖) assert(data == 42); // 断言可能失败 (data 不从 ptr 携带依赖) } 获取-释放序 若线程 A 中的一个原子存储带标签 memory_order_release，而线程 B 中来自同一变量的原子加载带标签 memory_order_acquire，则从线程 A 的视角先发生于原子存储的所有内存写入，在线程 B 中成为可见副效应，即一旦原子加载完成保证线程 B 能观察到线程 A 写入内存的所有内容。此顺序的典型使用场景是 互斥量 ::std::atomic\u003c::std::string*\u003e ptr; int data; void producer() { ::std::string* p = new ::std::string(\"Hello\"); data = 42; ptr.store(p, ::std::memory_order_release); } void consumer() { ::std::string* p2; while (!(p2 = ptr.load(::std::memory_order_acquire))); assert(*p2 == \"Hello\"); // 断言成功 assert(data == 42); // 断言成功 } 顺序一致性 带标签 memory_order_seq_cst 的原子操作不仅以与释放/获得顺序相同的方式排序内存 (在一个线程中先发生于存储的任何结果都变成进行加载的线程中的可见副效应)，还对所有带此标签的内存操作建立单独全序。 void write_x() { x.store(true, ::std::memory_order_seq_cst); } void write_y() { y.store(true, ::std::memory_order_seq_cst); } void read_x_then_y() { while (!x.load(::std::memory_order_seq_cst)); if (y.load(::std::memory_order_seq_cst)) { ++z; } } void read_y_then_x() { while (!y.load(::std::memory_order_seq_cst)); if (x.load(::std::memory_order_seq_cst)) { ++z; } } assert(z.load() != 0); // 断言成功 全序列顺序在所有多核系统上要求完全的内存栅栏 CPU 指令，这可能成为性能瓶颈，因为它强制受影响的内存访问传播到每个核心。 ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:3:2","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"栅栏 栅栏操作会对内存序列进行约束，使其无法对任何数据进行修改，典型的做法是与使用 memory_order_relaxed 约束序的原子操作一起使用。栅栏属于全局操作，执行栅栏操作可以影响到在线程中的其他原子操作，因为这类操作就像画了一条任何代码都无法跨越的线一样，所以栅栏操作通常也被称为 内存栅栏 (memory barriers)。我们以下代码与获取-释放序代码效果相同 ::std::atomic\u003c::std::string*\u003e ptr; int data; void producer() { ::std::string* p = new ::std::string(\"Hello\"); data = 42; ::std::atomic_thread_fence(::std::memory_order_release); ptr.store(p, ::std::memory_order_relaxed); } void consumer() { ::std::string* p2; while (!(p2 = ptr.load(::std::memory_order_relaxed))); ::std::atomic_thread_fence(::std::memory_order_acquire); assert(*p2 == \"Hello\"); // 断言成功 assert(data == 42); // 断言成功 } ","date":"2020-12-05","objectID":"/2020/cpp_concurrency_atomic/:3:3","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (2) – 原子操作","uri":"/2020/cpp_concurrency_atomic/"},{"categories":["C++"],"content":"GinShio | Cpp Concurrency in Action (2rd) 第二、三、四章读书笔记","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"线程管理 ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:1:0","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"创建线程 新的线程会在 ::std::thread (头文件 thread 中) 对象创建的时候被启动，在函数执行完毕后，该线程也就结束了，提供的函数对象会复制到新线程的存储空间中，函数对象的执行与操作都在线程的内存空间中执行。在创建新线程时你可以指定一个函数作为任务，或者是 仿函数 ，当然也可以是 lambda 表达式 ::std::thread my_thread0{do_something}; struct Task { void operator()() const { do_something(); } }; ::std::thread my_thread1{Task()}; ::std::thread my_thread2{[]() { do_something(); }}; 线程启动后，需要指定是 等待线程结束 还是 让其自主运行 ，如果 ::std::thread 对象销毁之前没有做出决定，程序就会终止，因此必须确保线程能够正确 汇入 (joined) 或 分离 (detached)。调用 join() 可以等待线程完成，并在线程结束时清理相关的内存，使 ::std::thread 对象不再与已完成线程有任何关联，所以一个线程一旦被汇入将不能再次汇入。调用 detach() 会使线程在后台运行，不再与主线程进行直接交互， ::std::thread 对象不再引用这个线程，分离的线程也不可被再次汇入，不过C++运行时库保证线程退出时可以正确回收相关资源。 在C++中 ::std::thread 对象是一种 可移动但不可复制 的资源，它可以交出它的所有权，但不能与其他对象共享线程的所有权。如果你希望对一个已持有线程的对象更改其行为，那你必须先汇入或分离已关联的线程，或者将已关联的线程的所有权交出。 ::std::thread t1{do_something}; ::std::thread t2 = std::move(t1); t1 = std::thread{some_other_function}; std::thread t3; t3 = std::move(t2); // t1 = std::move(t3); // 错误 ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:1:1","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"传递参数 向线程中传递参数十分简单，为 ::std::thread 构造函数附加参数即可，所有参数 将会拷贝到新线程的内存空间中，即使函数中的参数是引用 void f1(int i, const ::std::string\u0026 s); void f2(int i, ::std::string\u0026 s); ::std::thread t1{f1, 3, ::std::string{\"Hello\"}}; t1.join(); // ::std::thread t2{f2, 2, ::std::string{\"Hello\"}}; // 报错 // t2.join(); 这里 f2 期望传入一个::std::string的引用，传递参数时会将拷贝的参数以右值的方式进行传递 (为了支持移动的类型)，与函数期望的非常量引用不符，故会在编译期报错。不过我们可以使用 ::std::ref 将参数转换为引用的形式进行传递 auto s = ::std::string{\"Hello\"}; ::std::thread t2{f2, 6, ::std::ref(s)}; t2.join(); 当然也可以在一个线程上运行一个成员函数，做法也是很简单的，第一个参数传递成员函数的指针，第二个参数传递这个类的对象的指针，剩下的则是这个待运行的函数的参数 struct X { void do_something(int); } x; ::std::thread t3{\u0026X::do_something, \u0026x, 1}; ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:1:2","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"线程标识 线程的标识类型是 ::std::thread ::id ，可以使用 ::std::thread 对象的成员函数 get_id() 获取，当线程没有和任何执行线程关联时将返回默认值来表示 无线程; 也可以使用 ::std::this_thread::get_id() 来获取当前线程的标识。::std::thread ::id 对象可以拷贝或对比，因为标识符是可复用的，当两个标识符相等时代表 同一个线程 或这两个线程 无关联线程 if (master_thread_id == ::std::this_thread::get_id()) { master_do_something(); } else { worker_do_something(); } ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:1:3","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"共享数据 涉及到共享数据时，问题就是因为共享数据的修改所导致，如果共享数据只读，那么不会影响到数据，更不会对数据进行修改，所有线程都会获得同样的数据。但当一个或多个线程要修改共享数据时，就会产生很多麻烦，需要小心谨慎，才能确保所有线程都正常工作。 ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:2:0","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"条件竞争 并发中的竞争条件，取决于一个以上线程的执行顺序，每个线程都抢着完成自己的任务，大多数情况下，即使改变执行顺序，也是良性竞争，结果是可以接受的。遗憾的是，当不变量遭到破坏时会产生条件竞争，通常是恶性竞争：并发的去修改一个独立对象。恶性竞争时对一个数据块进行修改时，其他线程可能同时对其进行访问，导致数据不一致或与预期不符，并且出现概率低且难复现。 避免恶性竞争，最简单的方法就是对数据结构采用某种 保护机制, 确保只有修改线程可以看到不变量的中间状态，其他线程观察结构时会发现其修改还未开始。另一方式就是对数据结构与不变量进行修改，修改后的结构可以完成一系列不可分割的变量，从而保证不变量的状态，即 无锁编程 。 ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:2:1","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"互斥量 访问共享数据前将数据锁住，在访问结束后再将数据解锁，当线程使用互斥量锁住共享数据时，其他的线程都必须等到之前那个线程对数据进行解锁后，才能进行访问数据。 通过实例化 ::std::mutex (头文件 mutex 中) 创建互斥量实例，成员函数lock()可对互斥量上锁，unlock()为解锁，不过不推荐使用成员函数，因为你必须在函数的出口处正确的解锁，其中包括异常情况也必须保证正确解锁，否则互斥量可能无法正常使用。推荐的做法是使用互斥量RAII模板类 ::std::lock_guard (头文件 mutex 中)，构造时加锁并在析构时解锁，保证互斥量可以被正确的解锁。 下面例子中，如果多个线程访问add_n函数，那么互斥量mu就会保护变量 result ，在一个线程中修改它时其他线程将无法访问它， \\(result += i\\) 将会在线程中安全的执行，不会因为数据竞争导致线程看到的result脏值，从而污染结果 ::std::mutex mu; void add_n(const long long\u0026 n, long long\u0026 result) { for (long long i = 1ll; i \u003c= n; ++i) { ::std::lock_guard\u003c::std::mutex\u003e guard(mu); result += i; } } 不过通常互斥量会与需要保护的数据封装在同一个类中，让它们联系在一起，保证数据不变量的稳定状态。不过当类中某个方法返回保护数据的指针或者引用时，可能会破坏数据，此时需要谨慎的对接口进行设计，切勿将受保护数据的指针或引用传递到互斥锁作用域之外。 使用互斥量保护数据时，还需要考虑接口间的条件竞争，比如常使用的 ::std::stack，以下代码在单线程中是正确的，但是当 ::std::stack 是共享数据时，虽然每次调用接口时内部可能返回正确的结果，但是当用户使用时可能并非安全的。很明显代码中，top() 调用时很可能其他线程已经 pop() 了最后一个元素，虽然该线程访问到栈不为空，但是 top() 获取到错误的结果， top() 与 pop() 存在数据竞争关系 ::std::stack\u003cint\u003e s; if (!s.empty()) { const int value = s.top(); s.pop(); do_something(value); } 锁的粒度太小，恶性条件竞争已经出现，需要保护的操作并未全覆盖到; 如果锁的粒度太大，会抵消并发带来的性能提升。 死锁 使用多个互斥量操作时需要注意 死锁 ，这会让两个线程互相等待，直到另一个解锁互斥量。死锁产生的必要条件: 互斥条件 ：一个资源每次只能被一个任务使用 占有且等待 ：因请求资源而阻塞时，对已获得的资源保持不放 不可剥夺 ：已获得的资源，在末使用完之前，不能强行剥夺 循环等待条件 ：若干任务之间形成一种头尾相接的循环等待资源关系 一般在C++使用互斥量时，避免循环等待即可，对多个互斥量可以使用标准库中的 ::std::lock 与 ::std::lock_guard 进行RAII锁定，可以按照一定的顺序对互斥量进行锁定，避免循环锁定。以下代码展示了一次锁定多个互斥量，::std::lock 锁定互斥量，并创建两个 ::std::lock_guard 对象对互斥量进行管理，=::std::adopt_lock= 表示 ::std::lock_guard 可以获取锁并将锁交给其管理，::std::lock_guard 对象不需要再构建新的锁。值得一提的是，::std::lock 可能会抛出异常，但是请放心，已锁定的锁会随着异常而自动释放，所以 ::std::lock 要么 全部锁住 要么 一个都不锁 void swap(X\u0026 lhs, X\u0026 rhs) { if (\u0026lhs == \u0026rhs) { return; } ::std::lock(lhs.mu, rhs.mu); ::std::lock_guard\u003c::std::mutex\u003e lockl{lhs.mu, ::std::adopt_lock}; ::std::lock_guard\u003c::std::mutex\u003e lockr{rhs.mu, ::std::adopt_lock}; ::std::swap(lhs.data, rhs.data); } C++17 中提供了RAII模板类 ::std::scoped_lock (头文件 mutex 中) 用来支持这种情况，并且增加了 自动推导模板参数 ，是所以这种情况在 C++17 中将会更简单的实现 void swap(X\u0026 lhs, X\u0026 rhs) { if (\u0026lhs == \u0026rhs) { return; } ::std::scoped_lock guard{lhs.mu, rhs.mu}; // 等价于: // ::std::scoped_lock\u003c::std::mutex, ::std::mutex\u003e guard{lhs.mu, rhs.mu}; ::std::swap(lhs.data, rhs.data); } 死锁通常是对锁的使用不当造成，当然也可以是其他情况，不过我们应该尽可能的避免死锁 避免嵌套锁 ：获取一个锁时就别再获取第二个，需要获取多个锁时应使用 ::std::lock 来完成 避免在持有锁时调用外部代码 ：代码是由外部提供的，我们无法确定外部的行为，可能会造成与第一条违反的情况 使用固定顺序获取锁 ：当有多个锁且无法使用 ::std::lock 时，应在每个线程上以固定的顺序获取锁 灵活的管理锁 标准库提供了一种灵活的RAII管理锁的方式 ::std::unique_lock (头文件 mutex 中)，它允许使用 ::std::adopt_lock 假设已拥有互斥的所有权，也允许使用 ::std::defer_lock 假设不获取互斥的所有权，使用 ::std::unique_lock 会与 ::std::lock_guard 的实现方式等价。::std::unique_lock 对象中带有标志来确定是否持有互斥量，并确保正确地在析构函数中处理互斥量 void swap(X\u0026 lhs, X\u0026 rhs) { if (\u0026lhs == \u0026rhs) { return; } ::std::unique_lock\u003c::std::mutex\u003e lockl{lhs.mu, ::std::defer_lock}; ::std::unique_lock\u003c::std::mutex\u003e lockr{rhs.mu, ::std::defer_lock}; ::std::lock(lockl, lockr); // 持有的互斥量并锁定 ::std::swap(lhs.data, rhs.data); } ::std::unique_lock 是一种可移动不可复制的类型，它可以交出已持有互斥量的所有权，使互斥量在不同作用域中传递 ::std::unique_lock\u003c::std::mutex\u003e get_lock() { extern ::std::mutex mu; ::std::unique_lock\u003c::std::mutex\u003e lk{mu}; do_something(); return lk; } void other() { ::std::unique_lock\u003c::std::mutex\u003e lk{get_lock()}; do_something(); } ::std::unique_lock 还支持在对象销毁之前放弃持有互斥，这样可以提前为其他等待线程释放锁，增加性能。 锁的粒度是用来描述锁保护的数据量的大小， 细粒度锁 (fine-grained lock) 能够保护较小的数据量， 粗粒度锁 (coarse-grained lock) 能够保护较多的数据量。比如数据库中，对一行进行锁定的锁比对整张表锁定的锁粒度小，行锁相对于表锁性能更高，因为可以同时处理多行，但是也更不安全。 ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:2:2","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"保护共享数据的方式 保护共享数据的初始化过程 如果一个资源构造代价昂贵，我们可能会使用延迟初始化来构造它，不过这在单线程下是安全的，多线程下初始化是需要被保护的，不然可能会出现多次初始化的情况 void foo() { ::std::unique_lock\u003c::std::mutex\u003e lk{mu}; if (data.empty()) { data = new element(); } lk.lock(); do_something(); } 双重检测锁定模式 (DCLP) 也是一种保护初始化的状态，不过遗憾的是，它存在潜在的条件竞争，即线程可能得知其他线程完成了初始化，但可能没有看到新创建的实例，在调用do_something()时得到不正确的结果。Java引入了volatile关键字并安全地实现了DCLP，C++11开始我们也可以实现安全的DCLP。详细可以阅读 C++与双重检测锁定模式的风险，我们也可以在之后的学习中学习安全的DCLP实现 // DCLP void bar() { if (data.empty()) { ::std::lock_guard\u003c::std::mutex\u003e lk{mu}; if (data.empty()) { data = new element(); } } do_something(); // 数据竞争 } 不过我们可以不这么麻烦，C++标准库为我们提供了 ::std::once_flag 与 ::std::call_once (头文件 mutex 中) 来处理这种情况，并且相比使用互斥量所消耗的资源更少 ::std::once_flag once; void func() { ::std::call_once(once，[]() { data = new element(); }); do_something(); } 局部作用域中的static变量在声明后就已经完成初始化，对于C++11之前初始化的过程中存在条件竞争，但是从 C++11 之后开始初始化与定义完全在一个线程中发生 element get_element_instance() { static element instance; // C++11 开始为线程安全的初始化 return instance; } 保护不常更新的数据结构 当有不常更新的数据结构时，我们希望在修改时线程可以独占并安全的修改内容，完成修改后可以并发的安全访问数据。使用 ::std::mutex 来保护这样的数据结构对于性能来说并不是一个很好的方法，这会削弱读取数据的性能。我们可以想象这样一种互斥量，它可以在 写 线程中独占访问，而允许 读 线程并发访问，这样的互斥量被称为 读写锁 ，读线程需要等写线程释放锁后才可以并发访问，而写线程必须等全部读线程放弃互斥量后才可以独占访问。 C++17标准库提供了 ::std::shared_mutex (头文件 shared_mutex 中)，C++14提供了RAII模板类 ::std::shared_lock 与有时限的读写锁 ::std::shared_timed_mutex (头文件 shared_mutex 中)，可惜的是C++11中并没有提供相应的设施。timed_mutex系列互斥量相比普通互斥量，多了时限功能，在时限内可以获得锁则返回true并获得锁，否则返回false并不能获得锁，不过普通的互斥量则相较有更高的性能。在读写锁的使用中，对于写线程可以使用 ::std::lock_guard\u003c::std::shared_mutex\u003e 与 ::std::unique_lock\u003c::std::shared_mutex\u003e 进行RAII管理，它们与普通的互斥量行为一致；对于读线程，则需要 ::std::shared_lock\u003c::std::shared_mutex\u003e 进行RAII管理 class DnsCache { ::std::map\u003c::std::string，::std::string\u003e entries_; mutable std::shared_mutex mu_; public: ::std::string find(const ::std::string\u0026 domain) const { ::std::shared_lock\u003c::std::shared_mutex\u003e lk{mu_}; auto it = entries_.find(domain); return (it == entries_.end()) ? \"\" : it-\u003esecond; } void update(const ::std::string\u0026 domain, const ::std::string\u0026 ip) { ::std::lock_guard\u003c::std::shared_mutex\u003e lk{mu_}; entries_[domain] = ip; } }; 重入锁 在一个线程上，对已上锁的 ::std::mutex 再次上锁是错误的，会引起未定义行为，如果希望在线程上对一个互斥量在释放前进行多次上锁，则需要使用 ::std::recursive_mutex (头文件 mutex 中)。当然要牢记，你对其上锁了多少次，那一定需要解锁多少次，否则就会出现锁死其他线程的情况 (请善用 ::std::lock_guard 与 ::std::unique_lock) ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:2:3","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"同步操作 ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:3:0","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"等待条件 通过一条线程触发等待事件的机制是最基本的唤醒方式，这种机制被称为 条件变量 ，条件变量与多个事件或其他条件相关，并且一个或多个线程会等待条件的达成。当某些线程被终止时，为了唤醒等待线程，终止线程会向等待着的线程广播信息。 C++标准库实现了条件变量 (头文件 condition_variable 中) ::std::condition_variable 和 ::std::condition_variable_any ，它们需要与互斥量一起才能工作，前者需要和 ::std::mutex 一起工作，而 _any 后缀的条件变量可以和任何互斥量一起，但是相比普通条件变量更消耗系统资源。 ::std::mutex mu; ::std::queue\u003cdata_chunk\u003e q; ::std::condition_variable cond; void preparation() { while (more()) { const data_chunk data = get_data(); ::std::lock_guard\u003c::std::mutex\u003e lk{mu}; q.push(data); cond.notify_one(); } } void processing() { while (true) { ::std::unique_lock\u003c::std::mutex\u003e lk{mu}; cond.wait(lk, [] { return !q.empty(); }); data_chunk data = q.front(); q.pop(); lk.unlock(); process(data); if (is_last_chunk(data)) { break; } } } 以上代码就是一个条件变量的应用，执行情况如下 preparation 线程将获取数据，上锁互斥量并将数据压入队列 processing 线程必须对互斥量进行锁定，之后才能调用条件变量的成员函数 wait() 检查条件谓词，如果成立则继续，如果不成立将解锁互斥量并阻塞当前线程 preparation 线程调用 notify_one() 会唤醒 一个正在等待 的线程，调用后需要解锁互斥量，如果没有等待线程则无事发生，notify_one() 不会唤醒调用后开始等待的线程 如果 processing 线程被唤醒，则会重新获取锁，并再次进行条件谓词的检查 条件变量调用wait()的过程中，可能会多次检查条件谓词，并在谓词为true的情况下立即返回。另一点，等待线程可能会在不被其他线程通知的情况下被唤醒，这被称为 虚假唤醒 ，而虚假唤醒的数量和频率都是不确定的，所以条件谓词不建议有副作用。 ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:3:1","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"future 当线程需要等待特定事件时，某种程度上来说就需要知道期望的结果，线程会周期性的等待或检查事件是否触发，检查期间也会执行其他任务。另外，等待任务期间也可以先执行另外的任务，直到对应的任务触发，而后等待future的状态会变为就绪状态。future可能是和数据相关，也可能不是，当事件发生时，这个future就不能重置了。 C++标准库提供了两种future (头文件 future 中) ::std::future 和 ::std::shared_future ，它们与智能指针 ::std::shared_ptr 和 ::std::unique_ptr 十分类似。::std::future 只能与指定事件相关连，而 ::std::shared_future 可以关联多个事件，而实现中所有实例会同时变为就绪状态，并且可以访问与事件相关的数据。如果希望future与数据无关，则可以使用 void 的特化。future 像是线程通信，但是其本身并不提供同步访问，如果需要访问独立的future对象时则需要使用互斥量或类似同步机制进行保护，::std::shared_future 提供访问异步操作结果的机制，每个线程可以安全的访问自身 ::std::shared_future 对象的副本。 异步返回值 我们可以使用 ::std::async (头文件 future 中) 和 ::std::future 启动一个异步任务，获取线程的返回值，当然等待返回值的线程会阻塞，直到 ::std::future 就绪为止 int async_func(); void do_something(); int main(void) { ::std::future\u003cint\u003e ret = ::std::async(async_func); // 异步执行 async_func do_something(); ::std::cout \u003c\u003c \"Return: \" \u003c\u003c ::std::flush // 立即打印 \u003c\u003c ret.get() \u003c\u003c ::std::endl; // 阻塞，直到 future 就绪 } ::std::future 是否需要等待取决于绑定的 ::std::async 是否启动一个线程，或是否有任务正在进行，大多数情况下在函数调用之前可以传递一个 ::std::launch 类型的对象 ::std::launch::defered ：惰性求值，延迟到 wait() 或 get() 时进行求值 ::std::launch::async ：异步求值，求值将在一个独立的线程上进行 ::std::launch::async | ::std::luanch::defered ：默认行为，惰性求值或异步求值，具体求值方式由实现定义 auto f0 = ::std::async(::std::launch::async, func0); // 异步求值 auto f1 = ::std::async(::std::launch::defered, func1); // 惰性求值 auto f2 = ::std::async(::std::launch::async | ::std::launch::defered, func2); // 求值方式由实现定义 auto f3 = ::std::async(func3); // 求值方式由实现定义 绑定任务 ::std::packaged_task (头文件 future 中) 允许将 future 与可调用对象进行绑定，::std::packaged_task 的模板参数是一个可调用类型，在调用 ::std::packaged_task 时就会调用相关函数，而 future 状态就绪时则会存储返回值，通过 get_future() 获取绑定的 future 对象。 Promise 大部分并发编程语言都实现了 Promise/Future 结构，起源于函数式编程和相关范例，目的是将值与其计算方式分离，从而允许更灵活地进行计算，特别是通过并行化。后来它在分布式计算中得到了应用，减少了通信往返的延迟。future是变量的 只读 占位符视图，而promise是 可写 的单赋值容器，用于设置future的值。 类模板 ::std::promise (头文件 future 中) 提供存储值或异常的设施，之后通过 ::std::promise 对象所创建的 ::std::future 对象异步获得结果。::std::future 会阻塞等待线程，::std::promise 则会设置结果并将关联的 ::std::future 对象设置为就绪状态，不过 std::promise 只应当使用一次。 void accumulate(::std::vector\u003cint\u003e::iterator first, ::std::vector\u003cint\u003e::iterator last, ::std::promise\u003cint\u003e accumulate_promise) { int sum = ::std::accumulate(first, last, 0); accumulate_promise.set_value(sum); } int main(void) { ::std::vector\u003cint\u003e numbers = {1, 2, 3, 4, 5, 6}; ::std::promise\u003cint\u003e accumulate_promise; ::std::future\u003cint\u003e accumulate_future = accumulate_promise.get_future(); ::std::thread work_thread(accumulate, numbers.begin(), numbers.end(), ::std::move(accumulate_promise)); ::std::cout \u003c\u003c accumulate_future.get() \u003c\u003c ::std::endl; // 等待结果 work_thread.join(); } ::std::shared_future 可用于同时向多个线程发信息, 类似于 ::std::condition_variable::notify_all() ::std::promise\u003cvoid\u003e ready_promise, t1_promise, t2_promise; ::std::shared_future\u003cvoid\u003e ready_future{ready_promise.get_future()}; using high_resolution_clock = ::std::chrono::high_resolution_clock; using milli = ::std::chrono::duration\u003cdouble, ::std::milli\u003e; ::std::chrono::time_point\u003chigh_resolution_clock\u003e start; auto result1 = ::std::async(::std::launch::async, [\u0026, ready_future]() -\u003e milli { t1_promise.set_value(); ready_future.wait(); // 等待来自 main() 的信号 return high_resolution_clock::now() - start; }); auto result2 = ::std::async(::std::launch::async, [\u0026, ready_future]() -\u003e milli { t2_promise.set_value(); ready_future.wait(); // 等待来自 main() 的信号 return high_resolution_clock::now() - start; }); t1_promise.get_future().wait(); t2_promise.get_future().wait(); start = std::chrono::high_resolution_clock::now(); ready_promise.set_value(); std::cout \u003c\u003c \"Thread 1 received the signal \" \u003c\u003c result1.get().count() \u003c\u003c \" ms after start\\n\" \u003c\u003c \"Thread 2 received the signal \" \u003c\u003c result2.get().count() \u003c\u003c \" ms after start\\n\"; ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:3:2","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["C++"],"content":"限时等待 阻塞调用会将线程挂起一段不确定的时间，直到相应的事件发生，通常情况下这样的方式很不错，但是在一些情况下，需要限定线程等待的时间。 通常有两种指定超时方式：一种是 时间段 ，另一种是 时间点 。第一种方式，需要指定一段时间；第二种方式，就是指定一个时间点。多数等待函数提供变量，对两种超时方式进行处理，处理持续时间的变量 (时间段) 以 _for 作为后缀，处理绝对时间的变量 (时间戳) 以 _until 作为后缀。 时钟 时钟就是时间信息源，一个时钟的当前时间可由静态成员函数 now() 获取，特定的时间点的类型是成员类型 time_point 。时钟节拍被指定为1/x秒，这是由时间周期所决定，当时钟节拍均匀分布且不可修改时这种时钟被称为稳定时钟。 时间段 时间段 ::std::chrono::duration (头文件 chrono 中) 由 Rep 类型的 计次数 和 Period 类型的 计次周期 组成，计次周期是一个编译期有理数常量，表示从一个计次到下一个的秒数，比如分钟的类型可以使用 ::std::chrono::duration\u003clong long, ::std::ratio\u003c60, 1\u003e\u003e 表示，而毫秒的类型可以使用 ::std::chrono::duration\u003clong long, ::std::ratio\u003c1, 1000\u003e\u003e 表示。不过为了方便起见，标准库定义了辅助类型来简化使用： ::std::chrono::nanoseconds (纳秒)、 ::std::chrono::microseconds (微秒)、 ::std::chrono::milliseconds (毫秒)、 ::std::chrono::seconds (秒)、 ::std::chrono::minutes (分) 和 ::std::chrono::hours (时)。C++20开始，标准库又增加了天、周、月、年来方便使用时间段。 C++14中， ::std::literals 中定义了一些 duration 字面量方便使用 using namespace ::std::literals; auto one_day = 24h; // 24小时 auto half_an_hour = 30min; // 30分钟 auto five_seconds = 5s; // 5秒 auto one_second = 1000ms; // 1000毫秒 auto ten_micros = 10us; // 10微秒 auto two_nanos = 2ns; // 2纳秒 时间戳 时间戳 ::std::chrono::time_point (头文件 chrono 中) 由 Clock 类型的 时钟 和 Duration 类型的 时钟间隔 组成，并且可以通过算术运算调整时间戳。 std::chrono::system_clock::time_point now = std::chrono::system_clock::now(); std::time_t now_c = std::chrono::system_clock::to_time_t(now - std::chrono::hours(24)); std::cout \u003c\u003c \"24 hours ago, the time was \" \u003c\u003c std::put_time(std::localtime(\u0026now_c), \"%F %T\") \u003c\u003c ::std::endl; std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now(); std::cout \u003c\u003c \"Hello World\\n\"; std::chrono::steady_clock::time_point end = std::chrono::steady_clock::now(); std::cout \u003c\u003c \"Printing took \" \u003c\u003c std::chrono::duration_cast\u003cstd::chrono::microseconds\u003e(end - start).count() \u003c\u003c \"us.\\n\"; // 24 hours ago, the time was 2020-12-03 23:47:43 // Hello World // Printing took 4us. ","date":"2020-12-01","objectID":"/2020/cpp_concurrency_std/:3:3","tags":["Concurrency","笔记","编程语言"],"title":"C++ Concurrency (1) – 标准库","uri":"/2020/cpp_concurrency_std/"},{"categories":["Apps"],"content":"在服务器上搭建邮箱服务器","date":"2020-11-16","objectID":"/2020/mail_server/","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"搭建邮局服务器的想法之前一直都有，不过一直没有尝试，国庆的时候从阿里云换到了腾讯云的时候尝试直接使用 postfix 和 dovecot 搭建，尝试了大概3天被劝退了，重新使用现成的解决方案也算终于搭建好了，可以愉快的使用自建邮箱了 (可以愉快的装逼了 2020-11-18更新 更新了 mailu 的搭建，虽然 mailu 相比 mailcow 可以使用宿主机的数据库，不过 mailu 配置 SMTPS / IMAPS / POP3S 不如 mailcow 简单方便，也没怎么研究，目前没有切换到 mailu 的打算 ","date":"2020-11-16","objectID":"/2020/mail_server/:0:0","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"部署 开始搭建服务器，以下采用域名 (example.com) 和 IP (1.1.1.1)，安装在 /mailcow ，使用主机的nginx反向代理，部署之前我们首先定义一些Shell变量，以便之后使用，请根据自己的需求更改 path_to=\"/path/to\" mailcow_path=\"${path_to}/mailcow\" # mailcow 所在目录 mailu_path=\"${path_to}/mailu\" mail_host=\"mail.example.com\" mail_ip=\"1.1.1.1\" db_user=\"example_user\" # 数据库用户 (Mailu使用宿主机PostgreSQL时使用) db_passwd=\"example_password\" # 数据库密码 (Mailu使用宿主机PostgreSQL时使用) db_name=\"example_db\" # 数据库名称 (Mailu使用宿主机PostgreSQL时使用) http_port=\"8080\" https_port=\"8443\" cert_path=\"/ssl/path/to/cert/\" # 证书存放目录 cert_file=\"${cert_path}/cert.pem\" # 域名证书 key_file=\"${cert_path}/key.pem\" # 域名证书密钥 ca_file=\"${cert_path}/intermediate_CA.pem\" # 域名证书颁发者证书 另外，由于webmail对 S/MIME 与 PGP/MIME 的支持并不好，我们将在服务器上禁止webmail，使用本地的邮件客户端收发邮件，以便更好的使用加密、签名功能，如有需要请自行开启webmail。 ","date":"2020-11-16","objectID":"/2020/mail_server/:1:0","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"DNS DNS设置是一个邮件服务器的重中之重，为了让我们可以发出邮件和收到邮件，防止邮件被拒收或者进入垃圾箱被识别成垃圾邮件等，当然不是配置好了就不会进垃圾邮箱，不配置肯定会有问题。 类型 记录 记录值 A mail 1.1.1.1 MX @ mail.example.com (10) TXT @ v=spf1 a mx ip:1.1.1.1 -all TXT _dmarc v=DMARC1; p=reject; rua=mailto:admin@example.com; ruf=mailto:admin@example.com; adkim=s; aspf=s 除了上述DNS解析之外，还需要配置 DKIM 和 PTR ，DKIM在我们搭建好服务之后配置，PTR需要向运营商提交工单申请 (阿里云和腾讯云是这样的)，如果你没有配置ptr解析那么你可能会上一些黑名单。 ","date":"2020-11-16","objectID":"/2020/mail_server/:1:1","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"黑名单 在互联网上发送邮件不是可以为所欲为的，邮局服务有一套反垃圾邮件机制，当你的IP上了黑名单时，从这个IP发出去的邮件很容易进入垃圾邮箱或拒收，请珍惜自己的IP，不过可以尝试在检测上了哪些服务商的黑名单，并尝试解除黑名单，以下给出一些检测或申请去除反垃圾邮件网址 MXToolBox http://multirbl.valli.org/ Office 365 Barracuda ","date":"2020-11-16","objectID":"/2020/mail_server/:1:2","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"Mailcow:dockerized Mailcow:dockerized 是一个使用docker搭建的标准邮件服务器，集成了邮局、webmail、管理以及反垃圾邮件等功能，过程相对全面，不过缺点是比较吃资源，并且不支持 Synology/QNAP 或 OpenVZ 、 LXC 等虚拟化方式，并且不能使用 CentOS 7/8 源中的 Docker 包，要求真多。。。消耗资源的主要原因是 ClamAV 和 Solr ，即杀毒功能和搜索功能，如果不需要可以关闭。 资源 需求 CPU 1GHz RAM 最少4G (包含交换空间) 硬盘 20GiB (不包含邮件) 以下列出Mailcow:dockerized使用的端口 (HTTP和HTTPS为我们自定义的端口) 服务 协议 端口 容器 Postfix SMTP / SMTPS TCP 25 / 465 postfix-mailcow Postfix Submission TCP 587 postfix-mailcow Dovecot IMAP / IMAPS TCP 143 / 993 dovecot-mailcow Dovecot POP3 / POP3S TCP 110 / 995 dovecot-mailcow Dovecot ManageSieve TCP 4190 dovecot-mailcow HTTP / HTTPS TCP 80 / 443 nginx-mailcow 部署 Mailcow:dockerized 现在开始正式的搭建邮箱服务器 cd ${path_to} git clone https://github.com/mailcow/mailcow-dockerized mailcow \u0026\u0026 cd mailcow echo ${email_host} | ./generate_config.sh sed -ie \"s/HTTP_PORT=.*/HTTP_PORT=${http_port}/\" mailcow.conf # HTTP端口 sed -ie \"s/HTTPS_PORT=.*/HTTPS_PORT=${https_port}/\" mailcow.conf # HTTPS端口 sed -i \"s/TZ=.*/TZ=Asia\\/Shanghai/\" mailcow.conf # 时区 sed -i \"s/SKIP_LETS_ENCRYPT=.*/SKIP_LETS_ENCRYPT=y/\" mailcow.conf # 证书申请 (不需要) sed -i \"s/SKIP_SOGO=.*/SKIP_SOGO=y/\" mailcow.conf # webmail (不需要) sed -i \"s/SKIP_SOLR=.*/SKIP_SOLR=n/\" mailcow.conf # 搜索 (不需要) sed -i \"s/enable_ipv6: true/enable_ipv6: false/\" docker-compose.yml # 关闭ipv6 下面给出Nginx配置文件，Apache 配置文件请参见 官方文档 server { listen 80; listen [::]:80; server_name mail.example.com; return 301 https://$host$request_uri; } server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name mail.example.com; ssl_certificate /ssl/domain/cert.pem; ssl_certificate_key /ssl/domain/key.pem; ssl_session_timeout 2h; ssl_session_cache shared:mailcow:16m; ssl_session_tickets off; # See https://ssl-config.mozilla.org/#server=nginx for the latest ssl settings recommendations # An example config is given below ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5:!SHA1:!kRSA; ssl_prefer_server_ciphers off; location /Microsoft-Server-ActiveSync { proxy_pass http://127.0.0.1:8080/Microsoft-Server-ActiveSync; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_connect_timeout 75; proxy_send_timeout 3650; proxy_read_timeout 3650; proxy_buffers 24 256k; client_body_buffer_size 512k; client_max_body_size 0; } location / { proxy_pass http://127.0.0.1:8080/; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; client_max_body_size 0; } } 以上全部完成后，mailcow 基本配置完成，只需要启动起服务即可，默认用户密码 admin / moohoo cd ${mailcow_path} docker-compose pull docker-compose up -d 为 Mailcow:dockerized 配置 TLS 现在我们可以为SMTP与IMAP服务加入TLS，假设我们已经对域名 mail.example.com 申请了证书，对 postfix 与 dovecot 配置证书前，我们需要根据 postfix 文档先将我们自己的证书与提供商的证书按顺序存放在同一文件下，并且文件后缀为 .pem ，并存放在mailcow的ssl文件夹下 cat ${cert_file} ${ca_file} \u003e ${mailcow_path}/data/assets/ssl/cert.pem cp ${key_file} ${mailcow_path}/data/assets/ssl/key.pem 证书保存完毕后，对 postfix 与 dovecot 进行配置，配置完成重启服务即可 # postfix sed -i \"s/smtp_tls_security_level.*/smtp_tls_security_level = dane/\" data/conf/postfix/main.cf sed -i \"s/smtp_tls_CAfile.*/smtp_tls_CAfile = \\/etc\\/ssl\\/mail\\/cert.pem/\" data/conf/postfix/main.cf sed -i \"s/smtp_tls_cert_file.*/smtp_tls_cert_file = \\/etc\\/ssl\\/mail\\/cert.pem/\" data/conf/postfix/main.cf sed -i \"s/smtp_tls_key_file.*/smtp_tls_key_file = \\/etc\\/ssl\\/mail\\/key.pem/\" data/conf/postfix/main.cf sed -i \"s/smtpd_tls_security_level.*/smtpd_tls_security_level = may/\" data/conf/postfix/main.cf sed -i \"s/smtpd_tls_CAfile.*/smtpd_tls_CAfile = \\/etc\\/ssl\\/mail\\/cert.pem/\" data/conf/postfix/main.cf sed -i \"s/smtpd_tls_cert_file.*/smtpd_tls_cert_file = \\/etc\\/ssl\\/mail\\/cert.pem/\" data/conf/postfix/main.cf sed -i \"s/smtpd_tls_key_file.*/smtpd_tls_key_file = \\/etc\\/ssl\\/mail\\/key.pem/\" data/conf/postfix/main.cf # dovecot sed -i \"s/ssl_cert.*/ssl_cert = \u003c\\/etc\\/ssl\\/mail\\/cert.pem/\" data/conf/dovecot/dov","date":"2020-11-16","objectID":"/2020/mail_server/:1:3","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"Mailu.io Mailu 是一个使用docker搭建的轻量级标准邮件服务器，继承自poste.io，支持x86架构，集成了邮局、webmail、管理以及反垃圾邮件等功能。webmail可以选用roundcube、rainloop或禁止webmail，而数据库支持sqlite、MySQL与PostgreSQL，最重要的是 MySQL 和 PostgreSQL 可以选择使用镜像或宿主机 (1.9开始将删除docker镜像)。 资源 需求 CPU x86 RAM 建议2G 生成配置文件 Mailu官方提供了 在线生成配置文件，可以根据我们的需求生成配置文件，我们将使用 Docker-Compose 搭建 master 版本，并将生成的配置文件下载到服务器上。 initial configuration：进行初始化的配置，比如路径、主域名、TLS、管理界面等，由于我个人喜好自己生成TLS证书，所以选择 mail 禁止mailu帮我生成证书，但是对邮件进行TLS加密，如果需要mailu生成TLS证书选择带有 letsencrypt 的选项 pick some features：进行功能配置，我们禁用了webmail，可以根据个人喜好选择合适自己的webmail。剩下的三个选项分别是杀毒 (内存杀手)、WebDAV以及邮件代收，根据自己的需求选择 expose Mailu to the world：配置IP与主机名，监听地址填写自己的服务器IP，hostname填写服务器的长主机名 database preferences：数据库设置，这里我们选择使用宿主机的PostgreSQL，URL填写的是Docker在宿主机上默认开启的子网 部署 Mailu 现在开始正式的搭建邮箱服务器，假设你已经将配置文件下载到了 mailu_path 中，我们修改一下配置文件 sed -ie \"s/MESSAGE_SIZE_LIMIT=.*/MESSAGE_SIZE_LIMIT=100000000/\" mailu.env sed -i \"/::1/d\" docker-compose.yml sed -ie \"s/${mail_ip}://g\" docker-compose.yml sed -ie \"s/80:80/${http_port}:80/\" docker-compose.yml # HTTP端口 sed -ie \"s/443:443/${https_port}:443/\" docker-compose.yml # HTTPS端口 因为mailu配置的TLS选项是mail，所以我们使宿主机的Nginx反向代理到mailu-front监听的HTTP上即可 server { listen 80; listen [::]:80; server_name mail.example.com; return 301 https://$host$request_uri; } server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name mail.example.com; ssl_certificate /ssl/domain/cert.pem; ssl_certificate_key /ssl/domain/key.pem; # See https://ssl-config.mozilla.org/#server=nginx for the latest ssl settings recommendations ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5:!SHA1:!kRSA; ssl_prefer_server_ciphers off; ssl_session_timeout 2h; ssl_session_cache shared:mailu:8m; ssl_session_tickets off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; location / { proxy_pass http://127.0.0.1:8080/; } location /admin { proxy_pass http://127.0.0.1:8080/admin/; } # location /webmail { # proxy_pass http://127.0.0.1:8080/webmail/; # } } 宿主机的PostgreSQL也需要稍微配置一下 sudo adduser --disabled-login --gecos 'Mailu' ${db_user} sudo -u postgres -H psql -d template1 -c \"CREATE USER ${db_user}WITH PASSWORD '${db_passwd}' CREATEDB;\" sudo -u postgres -H psql -d template1 -c \"CREATE DATABASE ${db_name}OWNER ${db_user};\" sudo -u postgres -H psql -h localhost -d ${db_name} -c \"create extension citext;\" echo \"host ${db_name}${db_user}192.168.203.0/24 md5\" \u003e\u003e /etc/postgresql/12/main/pg_hba.conf sed -i \"s/#listen_addresses = 'localhost'/listen_addresses = '0.0.0.0'/\" /etc/postgresql/12/main/postgresql.conf systemctl restart postgresql 以上全部完成后 mailu 基本配置完成，只需要根据最后一步，启动起服务并设置管理员密码即可 cd ${mailu_path} docker-compose -p mailu up -d docker-compose -p mailu exec admin flask mailu admin admin ${mail_host#*.} PASSWORD ","date":"2020-11-16","objectID":"/2020/mail_server/:1:4","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"安全 我们已经配置了TLS，对于邮件的传输过程来说我们的邮件是安全的，但是对于服务提供商来说还是可以随意浏览我们的邮件内容的，如果你希望重要的内容不被服务商所浏览，可以尝试使用对邮件加密的方式。邮件加密并不是将邮件转换为一个带密码的文件，而是使用非对称加密套件，在MUA中进行加密、签名等，MTA只负责传输邮件而不能检测邮件的内容。如果你想使用加密的方式向我发送邮件，请保存以下公钥: OpenPGP S/MIME (iris@ginshio.org) S/MIME (ginshio78@gmail.com) 由于加密邮件是MUA行为，一般情况服务提供商的Webmail并不支持加密邮件，部分提供加密功能的提供商如果需要你上传私钥到他们的服务器，请保持警惕，私钥可以解密你的邮件。以下列出了常见的支持加密的MUA: Microsoft Outlook (S/MIME) Apple Mail (S/MIME) Mozilla Thunderbird (OpenPGP 和 S/MIME) KDE Kontact KMail (OpenPGP 和 S/MIME) GNOME Evolution (OpenPGP 和 S/MIME) Mutt (OpenPGP 和 S/MIME) ","date":"2020-11-16","objectID":"/2020/mail_server/:2:0","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"S/MIME 安全多功能互联网邮件扩展 (S/MIME) 是基于 PKI 的符合 X.509 格式的非对称密钥协议，提供了数字签名、加密功能。发送邮件时，数字签名会以 smime.p7s 的附件跟随邮件发送，如GMail的网页端就支持验证签名，如果是加密邮件则整封邮件被加密后以 smime.p7m 的附件发送。双方互发信息之前，如果没有对方公钥那么无法加密邮件，需要先互相发送签名的邮件用以交换公钥，导入公钥后可以开始发送加密邮件。你可以在 Actalis 申请为期一年的免费 S/MIME 证书，为你邮件加密开启第一步，请保存好申请到的证书 (.pfx文件)、密码以及CRP。 ","date":"2020-11-16","objectID":"/2020/mail_server/:2:1","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"OpenPGP OpenPGP标准是一种非对称的非对称密钥协议，提供了加密、签名等工程，OpenGPG是通过信任网络机制确保之间的密钥认证。相比于 S/MIME 而言，OpenGPG 在邮件方便被支持的更少，比如Gmail可以在webmail中验证S/MIME签名，但是并不支持 PGP/MIME。 ","date":"2020-11-16","objectID":"/2020/mail_server/:2:2","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"推荐阅读 Outlook 反垃圾邮件策略指南 SPF 记录：原理、语法及配置方法简介 DMARC 是什么？ 了解 S/MIME 电子邮件加密指南 在 Thunderbird 中使用 OpenPGP —— 怎么做以及问题解答 Mailcow:dockerized官方文档 使用 mailcow:dockerized 搭建邮件服务器 Mailu.io官方文档 ","date":"2020-11-16","objectID":"/2020/mail_server/:3:0","tags":["server","Application"],"title":"搭建邮箱服务器","uri":"/2020/mail_server/"},{"categories":["Apps"],"content":"GinShio | GPG 入门教程","date":"2020-11-14","objectID":"/2020/gpg_started_guide/","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"Pretty Good Privacy (PGP)，是一套用于讯息加密、验证的应用程序，由 Phil Zimmermann 于1991年发布，由一系列散列、数据压缩、对称密钥加密以及公钥加密的算法组合而成。GNU Privacy Guard (GPG)，是一个用于加密、签名通信内容以及管理非对称密钥的自由软件，遵循IETF订定的 OpenPGP技术标准 设计，并与PGP保持兼容。 GPG的基于现代密码学，主要是对非对称加密的应用，由于自己本身是菜鸡，又没有学过密码学，所以对于以下加密方式进行简单的介绍，如有不准确请指正。 对称加密 ：又称私钥加密，这类算法在加密与解密时使用 相同的 的密钥，通信双方在通信之前需要协商一个密钥。对称加密简单、高效，加密强度随密钥长度的增加而增加，常见加密算法 DES 、 ChaCha20 、 AES 等 非对称加密 ：又称公开密钥加密，这类算法采用公钥加密私钥解密，公钥可以随意发布，私钥必须由用户严格保管，通信双方在通信时使用对方的公钥加密自己的信息。非对称加密的数学基础是 超大整数的因数分解 、 整数有限域离散对数 、 椭圆曲线离散对数 等问题的复杂性。数字签名也是基于非对称加密实现，简单地说即将文件散列后使用私钥加密生成签名，验证时散列文件并与公钥解密签名的值做对比进行验证，数字签名可以验证文件完整性，也有防止伪造的作用。常见的加密算法有 DSA 、 RSA 、 ECDSA 等 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:0:0","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"初体验 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:1:0","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"生成 使用 --generate-key 参数可以创建一个使用默认值的密钥对，如果想设置更多的值可以使用 --full-generate-key 参数，如果再加上 --expert 开启专家模式，专家模式允许你自己选择 不同的加密算法 与 不同的密钥种类 ，在此仅介绍 --full-generate-key 参数。 选择你希望的密钥种类: 我们选择默认的 RSA and RSA ，会生成采用RSA算法且拥有加密、签名、验证功能的密钥 密钥长度: NIST建议 2030年之前推荐的最小密钥长度，对称加密 128bit ，非对称加密 2048bit ，椭圆曲线密码学 224bit 使用期限: 默认为永久(0)，在这里我们选择1天 (1) 我们生成了一个密钥对，可以看到一些关于新生成的密钥的信息，包括了密钥长度、uid、指纹，我们一般使用指纹来分别不同的密钥，指纹是用40位16进制数字表示的串，我们一般使用 邮箱 、 整串 或 串的最后16位 区分密钥。 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:1:1","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"备份 我们采用最朴素的方式保存密钥 —— 本地存储，但是请记住一点，私钥一定不能丢失或外泄。为了以防万一，我们生成一份 吊销证书 ，用以在特殊情况时吊销该密钥，当然吊销证书也应该妥善保管。 gpg -a --export EFC4B50FE8F8B2B3 \u003e test.pub # 导出公钥 gpg -a --export-secret-key EFC4B50FE8F8B2B3 \u003e test.sec # 导出私钥 gpg -a --gen-revoke EFC4B50FE8F8B2B3 \u003e test.rev # 生成吊销证书 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:1:2","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"发布 警告 将公钥发布到密钥服务器上是不可逆行为，请谨慎操作 首先列出常用的密钥服务器 sks-keyserver OpenPGP.org GnuPG.net MIT Ubuntu 我们可以从密钥服务器上查找、上传或导入公钥，如果我们已经上传了公钥，本地更新信息后需要再次上传将信息同步到服务器。需要注意的是，公钥服务器会不断同步公钥，不会因为你的密钥过期或吊销而删除。当你将公钥上传到服务器后，其他人可以很好获取你的公钥，完成一些实际用途。 gpg --keyserver pool.sks-keyservers.net --send-keys EFC4B50FE8F8B2B3 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:1:3","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"吊销 警告 吊销密钥是不可逆行为，请谨慎操作 吊销密钥是不可逆行为，当由于某些特殊原因，请吊销密钥并更新服务器上的密钥信息，尤其是私钥泄漏发生时请尽快吊销，吊销时将密钥生成的吊销证书导入gpg即可完成。 gpg --import test.rev # 吊销密钥 gpg --keyserver pool.sks-keyservers.net --send-keys EFC4B50FE8F8B2B3 # 更新吊销信息 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:1:4","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"深入了解 我们已经有了自己的密钥，那么接下来，我们先创建一个名为 alpha.txt 的文件，里面记录了大写字母A-Z，剩下的就交给GPG来做吧。 # 创建 alpha.txt echo \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \u003e alpha.txt ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:2:0","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"导入与删除 刚刚我们接触到了如何生成密钥，接下来我们还需要导入一些密钥，可能是其他人的，也可能是我们自己的。我们可以从密钥服务器上查找一些公钥，并导入到本地，我们使用 Debian Key Server 上举例的公钥 673A03E4C1DB921F 做演示 gpg --keyserver pool.sks-keyservers.net --search-keys 673A03E4C1DB921F # 查找公钥 gpg --keyserver pool.sks-keyservers.net --recv-keys 673A03E4C1DB921F # 导入公钥 对于一些本地的密钥，我们可以使用 --import 导入密钥，在使用 --list-keys 展示密钥时你会发现，每个密钥都有一个信任级别，这是一个十分复杂的概念，你可以将好友的GPG公钥签名后 (--sign-keys)，再上传到公钥服务器上，逐渐组成一个大的 信任网络 ，emmm…参见 Key Signing Party gpg --import test.sec # 导入之前备份的私钥 至于删除密钥，相对来说简单很多， --delete-keys 可以删除公钥， --delete-secert-keys 可以删除私钥 gpg --delete-keys EFC4B50FE8F8B2B3 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:2:1","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"加密与解密 加密与解密内容是我们申请RSA密钥的主要理由，我们可以将我们重要的数据加密、签名，然后发布到互联网上，这样没人可以知道你发布了什么，除非他获取到了你的私钥。 加密：参数 -e / --encrypt=，加密时使用 =-r / --recipient 指定密钥，加密文件时默认的加密文件为 alpha.txt.gpg gpg -er EFC4B50FE8F8B2B3 alpha.txt # 加密文件，输出到 alpha.txt.gpg gpg -er EFC4B50FE8F8B2B3 -o alpha.encrypt alpha.txt # 加密文件，输出到 alpha.encrypt md5sum alpha.txt | awk '{print $1}' - | gpg -aer EFC4B50FE8F8B2B3 - # 将文件的md5校验值加密输出到终端 解密：参数 -d / --decrypt=，使用 =-u / --local-user 指定密钥，解密文件时默认将解密的内容输出到终端中 gpg -du EFC4B50FE8F8B2B3 alpha.txt.gpg \u003e alpha.decrypt # 解密数据到 alpha.decrypt ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:2:2","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["Apps"],"content":"签名与校验 我们有时不需要对一些发布的文件进行加密，可以进行数字签名，表示这个文件是我发出的，并不是别人伪造的。签名时指定密钥的参数与解密相同 -u / --local-user ，数字签名的方式有多种，接下来依次介绍 二进制签名：参数 -s / --sign ，这种签名将源内容与签名存放在同一文件下，并以二进制的形式保存文件，默认输出文件为 alpha.txt.gpg gpg -u EFC4B50FE8F8B2B3 --sign alpha.txt 文本签名：参数 --clear-sign ，这种签名将源内容与签名存放在同一文件下，并以文本的形式保存文件，查看输出文件就可以发现源内容与签名存放在一起，默认输出文件为 alpha.txt.asc gpg -u EFC4B50FE8F8B2B3 --clear-sign alpha.txt 分离式签名：参数 -b / --detach-sign ，这种签名将源内容与签名存放在不同文件，签名与源文件可以分别发布，默认签名为二进制形式，默认输出文件名为 alpha.txt.sig 。如果需要文本形式的分离式签名可以加参数 -a / --armor ，此时默认输出文件名为 alpha.txt.asc gpg -u EFC4B50FE8F8B2B3 -b -o alpha.bin.sig alpha.txt # 二进制分离式签名 gpg -u EFC4B50FE8F8B2B3 -ab -o alpha.asc.sig alpha.txt # 文本分离式签名 签名加密同时进行：以上签名形式只进行签名，没有加密，以下介绍的方式可以让签名加密同时进行，但验证签名时只能直接解密同时验证签名，默认输出文件名为 alpha.txt.gpg gpg -u EFC4B50FE8F8B2B3 -r EFC4B50FE8F8B2B3 -se alpha.txt 签名就此介绍完了，如果我们需要验证他人的文件，需要先获取他们的公钥才可以开始验证文件，使用参数 --verify 对签名文件进行验证 gpg --verify alpha.txt.asc # 验证混合签名文件 对于分离式签名，后缀是 .asc 和 .sig 的文件，gpg会默认查找去除后缀后的文件名作为数据文件进行验证，也可以手动指定待验证的数据文件 gpg --verify alpha.bin.sig # 错误，没有文件 alpha.bin.sig cp alpha.asc.sig alpha.txt.asc.sig gpg --verify alpha.txt.asc.sig # 验证文件 'alpha.txt.asc'，签名损坏 cp alpha.asc.sig alpha.txt.sig gpg --verify alpha.txt.sig # 验证文件 'alpha.txt'，签名完好 gpg --verify alpha.bin.sig alpha.txt # 指定数据文件为 'alpha.txt'，使用 'alpha.bin.sig' 进行验证 ","date":"2020-11-14","objectID":"/2020/gpg_started_guide/:2:3","tags":["Application","Linux"],"title":"GPG 入门指北","uri":"/2020/gpg_started_guide/"},{"categories":["SICP"],"content":"GinShio | SICP第一章读书笔记","date":"2020-11-07","objectID":"/2020/sicp_001/","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":" 心智的活动，除了尽力产生各种简单的认识之外，主要表现在如下三个方面： 将若干简单认识组合为一个复杂认识，由此产生出各种复杂认识 将两个认识放在一起对照，不管它们如何简单或复杂，在这样做时并不将它们合二为一。由此得到有关它们相互关系的认识 将有关认识与那些实际中和它们同在的所有其他认识隔离开，这就是抽象，所有具有普遍性的认识都是这样得到的 我们准备学习的是有关 计算过程 的认识。计算过程是存在于计算机里的一类抽象事物，在其演化进程中，这些过程会去操作一些被成为 数据 的抽象事物。人们创造出一些名为 程序 的规则模式，以指导这类过程的进行。 ","date":"2020-11-07","objectID":"/2020/sicp_001/:0:0","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":"程序设计的基本元素 一个强有力的程序设计语言不仅是一种指挥计算机执行任务的方式，它还应该成为一种框架，使我们能够在其中组织自己有关计算过程的思维。当我们描述这个语言时，我们应该注意该语言提供的，将简单思维组合成复杂思维的方式。为此提供了三种机制: 基本表达形式 ：用于表示语言所关心的最简单的个体 组合的方法 ：将较简单的元素构造为复杂元素 抽象的方法 ：为复杂对象命名，将它们当作单元操作 数据是我们希望去操作的内容，过程是对操作这些数据的规则的描述，任何强有力的程序设计语言都必须能表述基本的数据与基本的过程，还需要提供对过程和数据进行 组合 和 抽象 的方法。 ","date":"2020-11-07","objectID":"/2020/sicp_001/:1:0","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":"过程作为黑箱 我们将一个问题自然的分解为若干子问题，这些子问题每一个都通过独立的过程完成，它们直接反映了原问题到子问题的分解。我们不需要关注子过程是如何实现计算过程的，将它看作一个 黑箱 ，只需要主要它最终可以完成原问题即可。 (define (square x) (* x x)) (define (square x) (exp (double (log x)))) (define (double x) (+ x x)) 以上这两个 square 过程，当我们只考虑返回值，那么它们是不可区分的。由此可见，一个过程应该能藏起一些细节，这将使过程的使用者不必自己去实现这些过程或弄清如何实现过程，作为一个黑箱而接受它。 形式参数的名称是用户不必关心的细节之一，形式参数的具体名称是什么完全不重要，它们也被成为 约束变量 ，过程的定义不受约束变量名称的改变而改变，约束变量被定义的那些表达式的集合称作 作用域 。 定义一个计算平方根的过程我们可能需要定义不同的子过程，最终将子过程组合起来完成最终问题的求解。在一个相当大的系统中，我们可能需要定义一系列子过程，这些子过程的名称可能发生冲突，我们希望将这些子过程局部化，将他们隐藏到主过程中。这种嵌套的定义称为 块结构 ，是最简单的一种解决冲突的方法。 (define (sqrt x) (define (good-enough? guess) (\u003c (abs (- (square guess) x)) 0.000000000001)) (define (improve guess) (average guess (/ x guess))) (define (sqrt-iter guess) (if (good-enough? guess) guess (sqrt-iter (improve guess)))) (sqrt-iter 1.0)) 可以发现，将过程定义在内部，因为x在sqrt的定义中是受约束的，其他过程也定义在sqrt中，即x的作用域中，它们都可以直接使用x，这被称为 词法作用域 。 ","date":"2020-11-07","objectID":"/2020/sicp_001/:1:1","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":"过程与它们所产生的计算 ","date":"2020-11-07","objectID":"/2020/sicp_001/:2:0","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":"线性的递归和迭代 考虑阶乘的计算 \\(n! = n \\cdot [(n - 1) \\cdot (n - 2) \\cdots 3 \\cdot 2 \\cdot 1] = n \\cdot (n - 1)!\\) ，我们可以翻译成以下过程 (define (factorial n) (if (or (= n 1) (= n 0)) 1 (* n (factorial (- n 1))))) 这个计算过程中，通过代换模型可以看出计算是一种先逐步展开而后收缩的形状，计算过程构造起一个 推迟进行的操作 所形成的链条，收缩阶段表现为这些运算的实际执行，这种计算过程被称为 递归计算过程 。如果要执行这个过程，解释器就必须维护好以后要执行的操作的轨迹，这个例子中推迟执行的乘法链条的长度也就是为保存其轨迹需要保存的信息量，这个长度随着n值的增加而线性增长，这个过程被称为 线性递归计算 。 (define (factorial n) (define (iter product counter) (if (\u003e counter n) product (fact-iter (* counter product) (+ counter 1) n))) (iter 1 1)) 这个计算过程中没有任何增长或收缩，计算过程的每一步，需要保存的轨迹就是变量 product 和 counter 的当前值，我们称这个过程为 迭代计算过程 。迭代计算过程就是那种其状态可以用固定数目的状态变量描述的计算过程，同时又存在一套固定的规则描述了计算过程从一个状态到另一个状态转换时状态变量的更新方式，还有一个结束状态的检测用以描述计算过程如何终止。计算阶乘的这一计算过程中，所需计算步骤随着n增长而线性增长，这个过程被称为 线性迭代计算 。 ","date":"2020-11-07","objectID":"/2020/sicp_001/:2:1","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":"树形递归 树形递归是另一种常见的计算模式，斐波那契数列就是如此计算模式，每个fibonacci调用中会有两次递归调用。 (define (fib n) (cond ((= n 0) 0) ((= n 1) 1) (else (+ (fib (- n 1)) (fib (- n 2)))))) 由于这种计算斐波那契数列的方法很糟糕，做了很多冗余计算，其递归次数跟随n的大小指数增加，因此我们需要使用迭代的方法来优化这个求解过程 (define (fib n) (define (fib-iter a b count) (if (= count 0) b (fib-iter (+ a b) a (- count 1)))) (fib-iter 1 0 n)) 树形递归计算过程并不是无用的，当考虑在层次结构性的数据上操作，而不是对数操作时，树形递归计算过程是一种自然、威力强大的工具，可以帮助我们理解与设计程序。 ","date":"2020-11-07","objectID":"/2020/sicp_001/:2:2","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":"增长的阶 不同的计算过程在消耗计算资源的速率上可能存在巨大差异，描述这种差异的方式采用 =增长的阶=，以便对某一计算过程所需资源进行粗略度量。 另 n 是一个参数，它作为问题规模的一种度量，令 \\(R(n)\\) 是一个计算过程在处理规模为n的问题时所需要的资源量。我们称 \\(R(n)\\) 具有 \\(\\Theta(f(n))\\) 的增长阶，记作 \\(R(n) = \\Theta(f(n))\\) ，读作 f(n)的theta ","date":"2020-11-07","objectID":"/2020/sicp_001/:2:3","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["SICP"],"content":"用高阶函数做抽象 通过以上的学习，我们了解到，过程也是一类抽象，它们描述了一些对于数的复合操作，但又不依赖与特定的数。人们总是对功能强大的程序设计语言有一个必然要求，即能为公共的模块命名，建立抽象，然后直接在抽象的层次上工作。这就是为什么大部分程序设计语言都包含定义过程的机制的原因。 即使在数值计算过程中，如果将过程限制为只能以数作为参数，那也将严重影响我们建立抽象的能力。我们有时需要构造出以过程为参数，或以过程为返回值的过程，这类能操作过程的过程称为 高阶过程 。 lambda方法可以使我们在需要的时候简便的创建出一个方法，而不用关系方法的名称。像任何以过程为值的表达式一样，lambda表达式可用作组合式的运算符，或者更一般的，可以用在任何通常使用过程名的上下文中。 ((lambda (x y z) (+ x y (* z z))) 1 2 3) 高阶过程的重要性，就在于使我们能显示地用程序设计语言的要素去描述这些抽象，使我们能像操作其他计算元素一样去操作它们。一般而言，程序设计语言总会对计算元素的可能使用方式强加上某些限制，带上最少限制的元素被称为 第一级 的状态，第一级元素的某些特权包括: 可以使用变量命名 可以提供给过程作为参数 可以由过程作为结果返回 可以包含在数据结构中 ","date":"2020-11-07","objectID":"/2020/sicp_001/:3:0","tags":["笔记","SICP"],"title":"SICP(1) – 构造过程抽象","uri":"/2020/sicp_001/"},{"categories":["编译原理"],"content":"GinShio | 编译原理第四章读书笔记","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"程序设计语言构造的语法可以使用 上下文无关文法 或者 BNF (巴库斯-瑙尔范式) 表示法来描述，文法为语言设计者和编译器编写者提供了很大便利: 文法给出了一个程序设计语言的精确易懂的语法归约 对于某些类型的文法，我们可以自动构造出高效的语法分析器，它能够确定一个源程序的语法结构。同时，语法分析器的构造过程可以揭示出语法的二义性，同时还可能发现一些容易在语言的初始设计阶段被忽略的问题 一个正确设计的文法给出了一个语言的结构，该结构有助于把源程序翻译为正确的目标代码，也有助于检测错误 一个文法支持逐步加入可以完成新任务的新语言构造，从而迭代地演化和开发程序语言。如果对语言的实现遵循语言的文法结构，那么在实现中加入这些新构造的工作就会变得更加容易 语法分析器从词法分析器获得一个词法单元组成的串，并验证这个串可以由源语言的文法生成，我们期望语法分析器能够以易于理解的方式报告语法错误，并能够从常见的错误中恢复并继续处理程序的其余部分。从概念上来说，对于良构的程序，语法分析器构造出一棵 语法分析树 ，并把它传递给编译器的其他部分进一步处理。我们并不需要显式地构造出语法分析树，对于源程序的检查和翻译工作可以和语法分析过程交替完成，因此语法分析器和其他部分可以用一个模块实现。 错误处理程序检测出错误后，必须报告在源程序的什么位置检测到错误，程序可能有不同层次的错误 词法错误 ：包括标识符、关键字或运算符拼写错误，或没有在n字符串文本上正确的添加引号 语法错误 ：包括分好、花括号的多余、缺失等，或 if-else 语句不匹配等 语义错误 ：包括运算符和运算分量之间的类型不匹配 逻辑错误 ：因程序员的错误推理而引起的任何错误，包括良构程序但结果不符合预期 语法分析器在检测出错误后，一般将自己恢复到某个状态，且有理由预期从那里开始输入将提供有意义的诊断信息，通常也会发现更多的错误，而不是检测到一个错误就退出程序，当然如果错误过多最好让编译器在达到某个错误数量上限后退出 恐慌模式的恢复 ：语法分析器一旦发现错误就不断丢弃输入的符号，直到找到 同步词法单元 (synchronizing token) 为止，同步词法单元通常是界限符 (如 ; 或 })，它们在源程序中清晰、无二义性。恐慌模式的错误纠正方法常常会跳过大量输入，不检查跳过部分可能包含的错误，但是实现足够简单且不会让语法分析陷入死循环 短语层次的恢复 ：当发现错误时，语法分析器可以在余下的输入上进行局部性纠正，即将余下输入的某个前缀替换为另一个串，使语法分析器可以继续分析。这个方法难以处理实际错误发生在检测位置之前的情况 错误产生式 ：通过预测可能遇到的常见错误，在当前语言的文法中加入特殊的产生式，这些产生式可以生产含有错误的构造，语法分析器就能检测到一个预期的错误，生成适当的错误诊断信息 全局纠正 ：处理一个错误的输入串时通过最少的改动将其转换为语法正确的串 ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:0:0","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"上下文无关文法 一个上下文无关文法由 终结符 、 非终结符 、一个 开始符号 和一组 产生式 组成 终结符：组成串的基本符号，与术语 词法单元名 为同义词，如 if-else 结构中的 if 和 else 非终结符：表示串的集合的语法变量，它们表示的串集合用于定义由文法生成的语言 开始符号：某个非终结符号，这个符号表示的串集合就是这个文法生成的语言 产生式：将终结符和非终结符组合为串的方法，每个产生式由以下元素组成 一个被成为产生式 头 或 左部 的 非终结符 ，头代表串的集合 符号 \\(\\rightarrow\\) ，有时也使用 ::= 来表示 一个由零或多个终结符与非终结符组成的 体 或 右部 ，体代表头所对应的串的某种构造方法 例如有一组生成式它们的头都是 E，我们可以将其组合在一起成 E \\(\\rightarrow\\) E + T | E - T | T 这种形式 E \\(\\rightarrow\\) E + T E \\(\\rightarrow\\) E - T E \\(\\rightarrow\\) T ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:1:0","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"符号约定 在对文法符号进行表示时，为了方便区分终结符与非终结符，我们对文法中的符号做以下约定 终结符 在字母表中排在前面的 小写字母 ，如a、b、c等 运算符 ，如+、-等 标点符号 ，如逗号、分号等 数字 黑体字符串 非终结符 在字母表中排在前面的 *大写字母*，如A、B、C等 *字母S*，它通常表示开始符号 小写的斜体字符串 字母表中排在后面的大写字母表示 文法符号 ，即表示非终结符或终结符，如X、Y、Z等 字母表中排在后面的小写字母表示 可能为空的终结符号串 ，如x、y、z等 除非特殊说明，第一个产生式的头就是开始符号 例如以下文法中我们可知，E、T 和 F 是非终结符，其中E是开始符号，其余符号是终结符 E \\(\\rightarrow\\) E + T | E - T | T T \\(\\rightarrow\\) T * F | T / F | F F \\(\\rightarrow\\) (E) | id ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:1:1","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"推导 推导就是由一连串的产生式组成，从开始符号开始，经过一系列产生式替换，从而形成了推导过程。考虑一个文法 \\(\\alpha A\\beta\\) ，其中 \\(\\alpha\\) 和 \\(\\beta\\) 是任意的文法符号串，A是非终结符，假设 \\(A \\rightarrow \\gamma\\) 是一个产生式，那么可以推导出 \\(\\alpha A \\beta \\Rightarrow \\alpha\\gamma\\beta\\) ，我们经常说的 经过零或多步推导出 使用符号 \\(\\xRightarrow{*}\\) 表示， 经过一步或多步推导出 使用符号 \\(\\xRightarrow{+}\\) 表示，并且有以下推论 对于任何串 \\(\\alpha\\) ， \\(\\alpha \\xRightarrow{*} \\alpha\\) 如果 \\(\\alpha \\xRightarrow{*} \\beta\\) 且 \\(\\beta \\xRightarrow{*} \\gamma\\) ，那么 \\(\\alpha \\xRightarrow{*} \\gamma\\) 如果 \\(S \\xRightarrow{*} \\alpha\\) ，其中 S 是文法G的开始符号，我们说 \\(\\alpha\\) 是 G 的一个 句型 (句型可能即包含终结符又包含非终结符，也可以是空串)，文法生成的语言是它所有句子的集合 (句子是不包含非终结符的句型)，由文法生成的语言被成为上下文无关语言，如果两个文法生成的语言相同那么这两个文法等价。推导过程有多种，我们最关心的是 最左推导 和 最右推导 ，即总是选择句型的最左/最右的非终结符进行替换，直到推导出句子，最左推导与最右推导存在一对一的关系，最左推导写作 \\(\\alpha \\xRightarrow[lm]{} \\beta\\) ，最右推导写作 \\(\\alpha \\xRightarrow[rm]{} \\beta\\) 。 语法分析树是推导过程的图形化表示，其中每个内部结点表示一个产生式的应用，标号为产生式的头，该结点的子结点的标号从左到右组成了推导过程中替换这个产生式的体。一棵树的叶子结点可以是终结符或非终结符， 从左到右将叶子结点排列起来就可以得到一个句型，这个句型被成为 结果 (yield) 或 边缘 (frontier)。例如产生式 E \\(\\rightarrow\\) E + E | E * E | -E | (E) | id ，则 -(id + id) 的语法分析树如下 ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:1:2","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"二义性 如果一个文法可以为某个句子生成多棵语法分析树，那么它就是有 二义性 (ambiguity)，即对同一个句子存在多个最左或最右推导文法。语法分析器都期望文法是无二义性的，需要消除文法中的二义性，可以选择抛弃不需要的语法生成树为每个句子留下一棵语法分析树。譬如上面产生式，可以推导出两种 id + id * id 的语法分析树，很明显第一棵树是正确的，乘法优先于加法进行计算，第二棵语法分析树错误的处理了加法与乘法的优先级。 ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:1:3","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"设计文法 文法能够描述程序设计语言的大部分语法，语法分析器接受的词法单元序列构成了程序设计语言的超集，编译器后续步骤必须对语法分析器的输出进行分析，以保证源程序遵守那些没有被语法分析器检查的规则。 文法是比正则表达式表达能力更强的表示方法，每个可以使用正则表达式描述的构造都可以使用文法来描述，反之不成立。为什么使用正则表达式来定义一个语言的词法语法？ 将一个语言的语法结构分为词法和非词法两个部分，可以很方便的将编译器前端模块化，将编译器分为词法分析器和语法分析器两个大小适中的部分 一个语言的词法规则通常很简单，不需要使用像文法这样的功能强大的表示方法来描述 与文法相比，正则表达式通常提供了 简洁 且 易于理解 的表示词法单元的方法 根据正则表达式自动构造得到的词法分析器效率要高于任意文法自动构造的到的分析器 相较来说，正则表达式更适合描述如标识符、常量、关键字等这样的语言构造的结构，文法最是和描述 嵌套结构 ，这样的嵌套结构不适合正则表达式描述。 ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:2:0","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"消除二义性 一个二义性文法有时也可以被改写为一个无二义性的文法，给出一个 if-then-else 文法， other 表示任何其他语句，这个文法在 悬空-else 结构中会出现二义性 stmt \\(\\rightarrow\\) if expr then stmt $\\qquad\\ $ | $\\ $ if expr then stmt else stmt $\\qquad\\ $ | other 可以构造出条件语句 if \\(E_{1}\\) then if \\(E_{2}\\) then \\(S_{1}\\) else \\(S_{2}\\) 的两棵不同的语法分析树，通常规则是每个 else 和最近且尚未匹配的 then 匹配，这个消除二义性规则可以用一个文法直接表示，但实践中很少用产生式表示这个规则。 这里我们给出 if-then-else 结构无二义性的文法 stmt \\(\\rightarrow\\) matched_stmt $\\ |\\ $ open_stmt matched_stmt \\(\\rightarrow\\) if expr then matched_stmt else matched_stmt $\\ |\\ $ other open_stmt \\(\\rightarrow\\) if expr then stmt $\\ |\\ $ if expr then matched_stmt else open_stmt ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:2:1","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"消除左递归 如果一个文法中存在一个非终结符A使得对某个串 \\(\\alpha\\) 存在一个推导 \\(A \\xRightarrow{+} A\\alpha\\) ，那么这个文法就是 左递归的 ，即产生式的右部的最左符号是非终结符A本身，自顶向下语法分析方法不能处理左递归的文法，因此需要一个方法来消除左递归。 左递归产生式 \\(A \\rightarrow A\\alpha | \\beta\\) ，不断应用这个产生式将在 A 的右边生成一个 \\(\\alpha\\) 的序列，当 A 最终被替换为 \\(\\beta\\) 时，就得到一个在 \\(\\beta\\) 后跟0或多个 \\(\\alpha\\) 的序列。使用一个新的非终结符 R，并按照以下方法改写 A 的产生式可以达到同样的效果，对于新产生式 \\(R \\rightarrow \\alpha R\\) 来说这是一个 右递归的 。 A \\(\\rightarrow\\) \\(\\beta\\) R R \\(\\rightarrow\\) \\(\\alpha\\) R | \\(\\varepsilon\\) 现在我们给出消除左递归的算法，如果文法中不存在 环 (如 \\(A \\xRightarrow{+} A\\) 的推导) 或 \\(\\varepsilon\\) 产生式 (如 \\(A \\rightarrow \\varepsilon\\) 的产生式)，就能保证能够消除左递归，伪代码如下 消除左递归 按某个顺序将非终结符排序为 \\(A_{1}, A_{2}, \\cdots, A_{n}\\) for i in (1, n): \\(\\qquad\\) for j in (1, i - 1): \\(\\qquad\\qquad\\) 将每个形如 \\(A_{i} \\rightarrow A_{i}\\gamma\\) 的产生式替换为产生式组 \\(A_{i} \\rightarrow \\delta_{1}\\gamma | \\delta_{2}\\gamma | \\cdots | \\delta_{k}\\gamma\\), \\(\\qquad\\qquad\\) 其中 \\(A_{j} \\rightarrow \\delta_{1} | \\delta_{2} | \\cdots | \\delta_{k}\\) 是所有的 \\(A_{j}\\) 产生式 \\(\\qquad\\) 消除 \\(A_{i}\\) 产生式之间的立即左递归 ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:2:2","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"提取左公因子 提取左公因子是一种文法转换方法，它可以产生适用于预测分析技术或自顶向下分析技术的文法。当不清楚应用在两个A产生式中如何选择时，我们可以通过改写产生式来推后这个决定，等我们读入了足够多的输入，获得足够信息后再做出正确选择。 如有文法 \\(A \\rightarrow \\alpha\\beta_{1} | \\alpha\\beta_{2}\\) ，输入的开头是从 \\(\\alpha\\) 推导得到的一个非空串，那么我们就不知道应该将A展开为 \\(\\alpha\\beta_{1}\\) 还是 \\(\\alpha\\beta_{2}\\) ，我们可以先将 A 展开为 \\(\\alphaB\\) ，从而将作出决定的时间推迟，在读入了从 \\(\\alpha\\) 推导得到的输入前缀之后，我们再决定将 B 展开为 \\(\\beta_{1}\\) 或 \\(\\beta_{2}\\) 。 提取左公因子 输入：文法G 输出：一个等价的提取了左公因子的文法 方法：对于每个非终结符A，找出它的两个或多个选项之间的最长公共前缀 \\(\\alpha\\) ，如果 \\(\\alpha \\neq \\varepsilon\\) ，那么存在一个非平凡的公共前缀将所有A的e产生式 \\(A \\rightarrow \\alpha\\beta_{1} | \\alpha\\beta_{2} | \\cdots | \\alpha\\beta_{n} | \\gamma\\) 替换为 \\(A \\rightarrow \\alpha A’ | \\gamma\\) \\(A’ \\rightarrow \\beta_{1} | \\beta_{2} | \\cdots | \\beta_{n}\\) 其中 \\(\\gamma\\) 表示所有不以 \\(\\alpha\\) 开头的产生式体， \\(A’\\) 代表新的非终结符，不断应用这个转换，直到所有非终结符的任意两个产生式体都不存在公共前缀为止。 ","date":"2020-11-03","objectID":"/2020/compilerprinciple_004/:2:3","tags":["笔记","龙书"],"title":"编译原理 (4) – 语法分析1","uri":"/2020/compilerprinciple_004/"},{"categories":["编译原理"],"content":"GinShio | 编译原理第三章读书笔记","date":"2020-10-17","objectID":"/2020/compilerprinciple_003/","tags":["笔记","龙书"],"title":"编译原理 (3) – 词法分析2","uri":"/2020/compilerprinciple_003/"},{"categories":["编译原理"],"content":"基于DFA的模式匹配器的优化 ","date":"2020-10-17","objectID":"/2020/compilerprinciple_003/:1:0","tags":["笔记","龙书"],"title":"编译原理 (3) – 词法分析2","uri":"/2020/compilerprinciple_003/"},{"categories":["编译原理"],"content":"NFA的重要状态 如果一个 NFA 状态有一个标号非 \\(\\varepsilon\\) 的离开转换，那么我们称这个状态为 重要状态 (important state)。子集构造法在计算 \\(\\varepsilon-closure(move(T，a))\\) 的时候，它只使用了集合T中的重要状态，也就是说只有当状态s是重要的，状态集合 \\(move(s,a)\\) 才可能是非空的。在子集构造法的应用过程中，两个NFA状态集合可以被认为是一致的条件是 具有相同的重要状态，且 要么都包含接受状态，要么都不包含接受状态 如果 NFA 是使用 McMaughton-Yamada-Thompson 算法根据一个正则表达式生成的，那么我们可以获得更多重要状态的性质 重要状态只包括在基础规则部分为正则表达式中某个特定符号位置引入的初始状态，即每个重要状态对应于正则表达式中的某个运算分量 NFA 只有一个接受状态，但该接受状态不是重要状态。我们可以在正则表达式r的右端连接一个独特的结束标记符 # ，使得r的接收状态增加一个在#上的转换，使其成为 (r)# 的NFA的重要状态 NFA 的重要状态直接对应于正则表达式中存放了字母表中符号的位置，使用抽象语法树来表示扩展的正则表达式是非常有用的 ","date":"2020-10-17","objectID":"/2020/compilerprinciple_003/:1:1","tags":["笔记","龙书"],"title":"编译原理 (3) – 词法分析2","uri":"/2020/compilerprinciple_003/"},{"categories":["编译原理"],"content":"抽象语法树 抽象语法树的叶子结点对应于运算分量，内部结点表示运算符。标号为 连接运算符 (\\(\\circ\\)) 的内部结点被称为 cat结点 ， 并运算符 (\\(|\\)) 的内部结点被称为 or结点 ， 星号运算符 (\\(*\\)) 的内部结点被称为 star结点 ，我们构建正则表达式 \\((a|b)^{*}abb\\#\\) 的抽象语法树。 抽象语法树的叶子结点可以标号为 \\(\\varepsilon\\) ，也可以用字母表中的符号作为标号，对于每个标号不为 \\(\\varepsilon\\) 的叶子结点，我们赋予一个独立的整数，我们将这个整数称作叶子结点的 位置 ，同时也表示和它对应的符号的位置，当然一个符号可以有多个位置。抽象语法树中的这些位置对应构造出的 NFA 中的重要状态。 ","date":"2020-10-17","objectID":"/2020/compilerprinciple_003/:1:2","tags":["笔记","龙书"],"title":"编译原理 (3) – 词法分析2","uri":"/2020/compilerprinciple_003/"},{"categories":["编译原理"],"content":"计算函数 要从一个正则表达式直接构造出 DFA，我们要先构造出它的抽象语法树，然后计算如下四个函数： nullable 、 firstpos 、 lastpos 和 followpos ，且这四个函数都用到了扩展正则表达式 (r)# 的抽象语法树。 nullable(n)：当且仅当此结点代表的子表达式的语言中包含空串 \\(\\varepsilon\\) 时抽象语法树结点n为真，即：这个子表达式可以生成空串或本身就是空串，即使它也可能表示其他串 firstpos(n)：定义了以结点n为根的子树中的位置集合，这些位置对应于以n为根的子表达式的语言中某个串的 第一个符号 lastpos(n)：定义了以结点n为根的子树中的位置集合，这些位置对应于以n为根的子表达式的语言中某个串的 最后一个符号 followpos(p)：定义了一个和位置p相关的、抽象语法树中的某些位置的集合。当且仅当存在 L((r)#) 中的某个串 \\(x=a_{1}a_{2}\\cdots a_{n}\\) ，使得我们在解释为什么x属于 L((r)#) 时，可以将x中的某个 \\(a_{i}\\) 和抽象语法树中的位置p匹配，且将位置 \\(a_{i+1}\\) 和位置q匹配，那么位置q在 \\(followpos(p)\\) 中。简单地说，该函数计算出位置n之后可以跟随的其他位置 在计算函数时，我们先给出较为简单的 nullable 、 firstpos 和 lastpos 的计算方式，我可可以使用一个对树的高度直接进行递归的过程来计算它们。 结点n nullable(n) firstpos(n) lastpos(n) 一个标号为 \\(\\varepsilon\\) 的叶子结点 true \\(\\emptyset\\) \\(\\emptyset\\) 一个位置为 i 的叶子结点 false {i} {i} 一个 or 结点， \\(n = c_{1}\\mid c_{2}\\) \\(nullable(c_{1})\\) or \\(nullable(c_{2})\\) \\(firstpos(c_{1}) \\cup firstpos(c_{2})\\) \\(lastpos(c_{1}) \\cup lastpos(c_{2})\\) 一个 cat 结点， \\(n = c_{1}c_{2}\\) \\(nullable(c_{1})\\) and \\(nullable(c_{2})\\) if (\\(nullable(c_{1})\\)) \\(firstpos(c_{1}) \\cup firstpos(c_{2})\\) else \\(firstpos(c_{1})\\) if (\\(nullable(c_{2})\\)) \\(lastpos(c_{1}) \\cup lastpos(c_{2})\\) else \\(lastpos(c_{2})\\) 一个 star 结点， \\(n=(c_{1})^{*}\\) true \\(firstpos(c_{1})\\) \\(lastpos(c_{1})\\) followpos 的概念有些复杂，我们先来了解如何计算 followpos，只有两种情况会使得正则表达式的某个位置跟在另一个位置之后 如果 n 是 cat 结点，且其左右子结点分别是 \\(c_{1}\\) 和 \\(c_{2}\\) ，那么对于 \\(lastpos(c_{1})\\) 中的每个位置 i， \\(firstpos(c_{2})\\) 中的所有位置都在 \\(followpos(i)\\) 中 如果 n 是 star 结点，且 i 是 \\(lastpos(n)\\) 中的一个位置，那么 \\(firstpos(n)\\) 中的所有位置都在 \\(followpos(i)\\) 中 四个函数如何计算都已经给出，现在我们用正则表达式 \\((a|b)^{*}abb\\#\\) 练练手，下图给出构建出的语法分析树，结点左边给出其 firstpos*，结点右边给出其 *lastpos followpos 的计算规则1要求我们查看每个cat结点，并将它的右子结点的firstpos中的每个位置放到它的左子结点的lastpos中各个位置的followpos中；计算规则2要求我们查看每个 star 结点，并将它的firstpos中的所有位置放到它的lastpos中各个位置的followpos中。例如上图中最下面的一个 cat 结点，根据规则1，将位置3加入到 followpos(1) 和 followpos(2) 中。 位置n followpos(n) 1 {1,2,3} 2 {1,2,3} 3 {4} 4 {5} 5 {6} 6 \\(\\emptyset\\) 我们可以创建有向图来表示函数 followpos，其中每个位置有一个对应的结点，当且仅当j在followpos(i)中时从位置i到位置j有一条有向边。那么这个表示followpos函数的有向图几乎就是相应正则表达式的不含 \\(\\varepsilon\\) 转换的NFA，我们经过以下处理即可由有向图得到NFA 将根结点的firstpos中的所有位置设置为开始状态 在每条从i到j的有向边上添加位置i上的符号作为标号 把和结尾 # 相关的位置当作唯一的接收状态 ","date":"2020-10-17","objectID":"/2020/compilerprinciple_003/:1:3","tags":["笔记","龙书"],"title":"编译原理 (3) – 词法分析2","uri":"/2020/compilerprinciple_003/"},{"categories":["编译原理"],"content":"从正则表达式构造DFA 接下来我们给出算法，直接从正则表达式构造DFA 技巧 输入：一个正则表达式 r 输出：一个识别 L(r) 的 DFA D 方法： 根据扩展的正则表达式 (r)# 构造出一颗抽象语法树 T 计算T的函数 nullable，firstpos，lastpos 和 followpos 构造出 D 的 状态集 \\(D_{states}\\) 和 D 的 转换函数 \\(D_{tran}\\) ，D的状态就是T中的位置集合，开始状态是 \\(firstpos(n_{0})\\) (\\(n_{0}\\) 是T的根节点)，接受状态集合是那些包含了和结束标记#对应的位置的状态。每个状态最初都是 未标记的 ，当我们开始考虑某个状态的离开转换时，该状态就变为 已标记的 构造的伪代码如下: while Dstates 中存在未标记的状态S: 标记 S for 每个输入符号a: 令 U 为 S 中和 a 对应的所有位置p的 followpos(p) 的并集 if U 不在 Dstates 中: 将 U 作为未标记的状态加入 Dstates 中 Dtran[S，a] = U 依然以 \\((a|b)^{*}abb\\) 为例构造 DFA，正则表达式所构造出的语法分析树上面已有，分析语法分析树可知只有 star 结点的 nullable 为真。 这颗树的根结点的 firstpos 集为 {1,2,3} ，即 DFA 的开始状态集合，我们称这个集合为 A。计算 \\(D_{tran}[A，a]\\) 和 \\(D_{tran}[A，b]\\) ，A中1和3对应于a，2对应于b，所有 \\(D_{tran}[A，a] = followpos(1) \\cup followpos(3) = {1，2，3，4}\\) ， \\(D_{tran}[A，b] = followpos(2) = {1,2,3}\\) ，以此类推，构造出该正则表达式的 DFA。 名称 集合 a b A {1,2,3} B A B {1,2,3,4} B C C {1,2,3,5} B D D {1,2,3,6} B A ","date":"2020-10-17","objectID":"/2020/compilerprinciple_003/:1:4","tags":["笔记","龙书"],"title":"编译原理 (3) – 词法分析2","uri":"/2020/compilerprinciple_003/"},{"categories":["编译原理"],"content":"最小化DFA 对于同一个语言，可以存在多个识别此语言的DFA。对于不同的DFA，各个状态的的名字可能不同，状态的个数也可能不一样，如果我们使用DFA实现词法分析器，则希望DFA的状态数尽可能的少，因为词法分析器的转换表需要为每个状态分配条目。 状态名如果不同，但只改变状态名就可以将一个自动机转换为另一个自动机，那么这两个自动机是 同构的 ，反之则不是。有一个重要结论：任何正则语言都有一个 唯一的 且 状态数目最少 的DFA，而且从任意接受相同正则语言的DFA出发，通过分组合并等价状态，我们总可以构造出状态数最少的DFA。 我们以正则表达式 \\((a|b)^{*}abb\\) 的两个已经构造出的DFA来讲解最小化，其中最小化的DFA是本篇中由正则表达式直接构造出的DFA，另一个非同构DFA是上一篇中由NFA转换来的DFA。 在最小化DFA之前，先说明输入串是如何区分各个状态的，如果分别从状态s和t出发，沿着标号为x的路径到达的两个状态只有一个是接受状态，则串x 区分状态 s 和 t；如果状态 s 和 t 存在能够区分它们的串，那么它们就是 可区分的 。空串 \\(\\varepsilon\\) 可以区分如何一个接受状态和非接受状态。串 bb 区分状态 A 和 B，因为从 A 出发经过标号 bb 的路径会到达非接受状态 C，而从B出发可以到达接受状态。 DFA状态最小化的工作原理是将一个DFA的状态集合划分为多个组，每个组中的各个状态相互不可区分，但不同组的状态是可区分的，每个组中的状态合并为最小DFA的一个状态，当任意一个组都不能再被分解为更小的组时这个划分结束，此时我们就得到了状态最少的DFA。具体方法如下 首先构造包含两个组 F 和 S-F 的初始划分 \\(\\Pi\\) ，这两个组分别是D的接受状态组和非接受状态组 应用以下方法构造新的分划 \\(\\Pi_{new}\\) Pi_new = Pi for Pi 中的每个组 G: 将 G 划分为更小的组，当且仅当对于所有的输入符号a，使得两个状态s和t在同一小组中，状态s和t在a上的转换都到达 Pi 中的同一组 在 Pi_new 中将 G 替换为对 G 进行划分得到的那些小组 如果 \\(\\Pi_{new} = \\Pi\\) ，令 \\(\\Pi_{final} = \\Pi\\) 并执行步骤4，否则用 \\(\\Pi_{new}\\) 替换 \\(\\Pi\\) 并重复步骤2 在划分 \\(\\Pi_{final}\\) 的每个组中选取一个状态作为该组的代表，这些代表构成了状态最少 DFA 的状态。最小状态DFA \\(D’\\) 的其他部分按如下步骤构造 \\(D’\\) 的开始状态是包含了 D 的开始状态的组的代表 \\(D’\\) 的接受状态是那些包含了 D 的接受状态的组的代表。每个组要么只包含了接受状态，要么只包含了非接受状态，因为我们一开始将这两类状态分开了 令 s 是 \\(\\Pi_{final}\\) 中某个组 G 的代表，并令 DFA 中正在输入 a 上离开 s 的转换到达状态 t，令 r 为 t 所在组 H 的代表，那么在 \\(D’\\) 中存在一个从 s 到 r 在输入 a 上的转换 上述算法可能会产生一个带有 死状态 的DFA，所谓死状态是在所有输入符号上都转向自己的非接受状态。我们可以消除掉死状态，使这个DFA可能会变为缺少某些转换的自动机。 ","date":"2020-10-17","objectID":"/2020/compilerprinciple_003/:1:5","tags":["笔记","龙书"],"title":"编译原理 (3) – 词法分析2","uri":"/2020/compilerprinciple_003/"},{"categories":["Apps"],"content":"在服务器上搭建一些自己用的到的服务","date":"2020-10-13","objectID":"/2020/service/","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"个人使用的是腾讯云的轻量服务器，系统镜像选择的是 Ubuntu 20.04，搭建的服务有 博客 HUGO 、私有网盘 Nextcloud 以及 Git服务器 GitLab 一下服务搭建时，域名统一使用 example.com，请根据自己的情况修改对应的配置，用到一些基础依赖请自行安装 Nginx Git PHP PostgreSQL Redis 我们首先定义一些变量，以便后边使用和修改 fpm_path=\"/etc/php/7.4/fpm\" # php-fpm 根目录 nextcloud_path=\"/path/to/nextcloud\" # nextcloud 所在目录 nextcloud_host=\"example.com\" nextcloud_db_user=\"nextcloud\" # Nextcloud 数据库用户 nextcloud_db_passwd=\"YourPassword\" # Nextcloud 数据库密码 nextcloud_db_name=\"nextcloud\" # Nextcloud 数据库名称 gitlab_path=\"/home/git/gitlab\" gitaly_path=\"/home/git/gitaly\" gitlab_host=\"example.com\" gitlab_db_passwd=\"YourPassword\" # GitLab 数据库密码 ","date":"2020-10-13","objectID":"/2020/service/:0:0","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Nextcloud Nextcloud 是 ownCloud 项目的一个分支，一个开源的私有云盘应用，官方提供了包括 桌面以及移动系统的客户端。 ","date":"2020-10-13","objectID":"/2020/service/:1:0","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Nextcloud 依赖 Nextcloud 依赖 PHP 运行时以及数据库 (MySQL 5.7+ / MariaDB 10.2+ 或 PostgreSQL) apt install -y nginx postgresql \\ php php-fpm php-cli php-mysql php-pgsql php-sqlite3 php-redis \\ php-apcu php-memcached php-bcmath php-intl php-mbstring php-json php-xml \\ php-curl php-imagick php-gd php-zip php-gmp php-ctype php-dom php-iconv php-zlib PHP: 修改 php-fpm 的配置文件 cd ${fpm_path} # php config sed -i \"s/memory_limit = .*/memory_limit = 512M/\" php.ini sed -i \"s/;date.timezone.*/date.timezone = UTC/\" php.ini sed -i \"s/;cgi.fix_pathinfo=1/cgi.fix_pathinfo=1/\" php.ini sed -i \"s/upload_max_filesize = .*/upload_max_filesize = 4096M/\" php.ini sed -i \"s/post_max_size = .*/post_max_size = 4096M/\" php.ini sed -i \"s/max_input_time = .*/max_input_time = 480/\" php.ini sed -i \"s/max_execution_time = .*/max_execution_time = 360/\" php.ini sed -i \"s/pm.max_children = .*/pm.max_children = 32/\" pool.d/www.conf sed -i \"s/pm.min_spare_servers = .*/pm.min_spare_servers = 1/\" pool.d/www.conf sed -i \"s/pm.max_spare_servers = .*/pm.max_spare_servers = 8/\" pool.d/www.conf sed -i \"s/pm.start_servers = .*/pm.start_servers = 4/\" pool.d/www.conf sed -i \"s/;clear_env = no/clear_env = no/\" pool.d/www.conf # opcache config sed -i \"s/;opcache.enable=1/opcache.enable=1/\" php.ini sed -i \"s/;opcache.memory_consumption=128/opcache.memory_consumption=128/\" php.ini sed -i \"s/;opcache.interned_strings_buffer=8/opcache.interned_strings_buffer=8/\" php.ini sed -i \"s/;opcache.max_accelerated_files=10000/opcache.max_accelerated_files=10000/\" php.ini sed -i \"s/;opcache.revalidate_freq=2/opcache.revalidate_freq=1/\" php.ini # apc config echo \"[apc]\" \u003e\u003e php.ini echo \"apc.cache_by_default = on\" \u003e\u003e php.ini echo \"apc.enable_cli = off\" \u003e\u003e php.ini echo \"apc.enable = on\" \u003e\u003e php.ini echo \"apc.file_update_protection = 2\" \u003e\u003e php.ini # restart systemctl restart php7.4-fpm PostgreSQL：创建用户 nextcloud 和数据库 nextcloud_db adduser --disabled-login --gecos 'Nextcloud' ${nextcloud_db_user} sudo -u postgres -H psql -c \"CREATE USER ${nextcloud_db_user}WITH PASSWORD ${nextcloud_db_passwd}'\" sudo -u postgres -H psql -c \"CREATE DATABASE ${nextcloud_db_name}OWNER ${nextcloud_db_user}\" Nginx：配置网站，修改 官方示例配置文件 并保存在 /etc/nginx/sites-available/nextcloud ln -sf /etc/nginx/sites-available/nextcloud /etc/nginx/sites-enabled/ nginx -t # 检查配置文件 systemctl restart nginx ","date":"2020-10-13","objectID":"/2020/service/:1:1","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Nextcloud 安装 下载 你需要的版本并解压到目录中 sudo chown -R www-data:www-data ${nextcloud_path} sudo -u www-data -H mkdir -p ${nextcloud_path} 准备工作完成后，进入网页，设置管理员帐号和数据库。 ","date":"2020-10-13","objectID":"/2020/service/:1:2","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Nextcloud 开启邮件服务 配置邮箱服务器前需要先修改nextcloud的代码，如下 cd /path/to/nextcloud sed -i \\ \"s/\\$streamContext = .*;/\\$streamContext = stream_context_create(array('ssl'=\u003e['verify_peer'=\u003efalse, 'verify_peer_name'=\u003efalse, 'allow_self_signed'=\u003etrue]));/\" \\ 3rdparty/swiftmailer/swiftmailer/lib/classes/Swift/Transport/StreamBuffer.php systemctl restart php7.4-fpm 登录管理员帐号进行邮箱服务器配置即可 字段 值 发送模式 SMTP 加密 SSL/TLS 来自地址 noreply@example.com 认证方式 登录 需要认证 true 服务器地址 mail.example.com:465 证书 noreply@example.com 密码 YourPassword ","date":"2020-10-13","objectID":"/2020/service/:1:3","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Nextcloud 插件 Nextcloud 不仅自带了很多功能，也提供了插件用于扩展功能，官方称作 Apps，以下个人推荐一些插件，欢迎补充 Announcement center ：公告发布 Registration ：注册功能 File access control ：文件访问控制，可以添加规则来控制管理用户对文件的操作，参见 工作流 Music ：音乐播放器 Full text search ：全文搜索 ","date":"2020-10-13","objectID":"/2020/service/:1:4","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"GitLab GitLab 是开源的基于git的 web DevOps生命周期工具 ，提供了 Git仓库 、 问题追踪 和 CI/CD 等功能。分为社区版和企业版，使用相同内核，部分功能社区版没有提供。Gitlab 相较消耗资源，官方推荐的最低要求为 4C4G 可以最多支持500用户， 8C8G 最多支持1000用户，具体的使用受到 用户的活跃程度 、 CI/CD 、 修改大小 等因素影响。 由于暂时不需要，没有安装 Gitlab Pages，Gitlab的安装依赖 git 用户，以下是目录结构 |-- home | |-- git | |-- .ssh | |-- gitaly | |-- gitlab | |-- gitlab-shell | |-- gitlab-workhorse | |-- repositories ","date":"2020-10-13","objectID":"/2020/service/:2:0","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Gitlab 组件 Gitaly：处理所有的 git 操作 GitLab Shell：处理基于 SSH 的 git 会话 与 SSH密钥 GitLab Workhorse：反向代理服务器，处理与Rails无关的请求，Git Pull/Push 请求 和 到Rails的连接，减轻Web服务的压力，帮助整体加快Gitlab的速度 Unicorn / Puma：Gitlab 自身的 Web 服务器，提供面向用户的功能，Gitlab 13.0 起默认使用 Puma Sidekiq：后台任务服务器，从Redis队列中提取任务并进行处理 GitLab Pages：允许直接从仓库发布静态网站 Gitlab Runner：Gitlab CI/CD 所关联的任务处理器 Nginx：Web服务器 PostgreSQL：数据库 ","date":"2020-10-13","objectID":"/2020/service/:2:1","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Gitlab 依赖 目前Gitlab最新版本为 v13.x ，我们安装最新版本 Ruby v2.6 or later GoLang v1.13 or later Git v2.24 (推荐 v2.28) or later Node.js v10.13.0 (推荐 v12) or later yarn v1.10.0 or later Nginx Redis v4.0 (推荐v5.0) or later PostgreSQL v11 or later 安装相关依赖，建立数据库，将 Redis 设置为 Unix Domain Socket (UDS) 连接 apt update -y \u0026\u0026 apt upgrade -y # 安装依赖 sudo apt install -y build-essential zlib1g-dev libyaml-dev libssl-dev libgdbm-dev libre2-dev \\ libreadline-dev libncurses5-dev libffi-dev curl openssh-server checkinstall libxml2-dev \\ libxslt-dev libcurl4-openssl-dev libicu-dev logrotate rsync python-docutils pkg-config \\ cmake vim runit postfix libimage-exiftool-perl golang nodejs # Ruby sudo gem install bundler --no-document --version '\u003c 2' # Node.js curl --silent --show-error https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | \\ sudo tee /etc/apt/sources.list.d/yarn.list sudo apt-get update sudo apt-get install yarn # 数据库 sudo adduser --disabled-login --gecos 'GitLab' git sudo -u postgres psql -d template1 -c \"CREATE USER git WITH PASSWORD '${gitlab_db_passwd}' CREATEDB;\" sudo -u postgres psql -d template1 -c \"CREATE EXTENSION IF NOT EXISTS pg_trgm;\" sudo -u postgres psql -d template1 -c \"CREATE EXTENSION IF NOT EXISTS btree_gist\"; sudo -u postgres psql -d template1 -c \"CREATE DATABASE gitlabhq_production OWNER git;\" # Redis sudo apt install redis-server sudo cp /etc/redis/redis.conf /etc/redis/redis.conf.orig sudo sed 's/^port .*/port 0/' /etc/redis/redis.conf.orig | sudo tee /etc/redis/redis.conf echo 'unixsocket /var/run/redis/redis.sock' | sudo tee -a /etc/redis/redis.conf echo 'unixsocketperm 770' | sudo tee -a /etc/redis/redis.conf sudo mkdir -p /var/run/redis sudo chown redis:redis /var/run/redis sudo chmod 755 /var/run/redis if [ -d /etc/tmpfiles.d ]; then echo 'd /var/run/redis 0755 redis redis 10d -' | sudo tee -a /etc/tmpfiles.d/redis.conf fi sudo systemctl restart redis sudo usermod -aG redis git ","date":"2020-10-13","objectID":"/2020/service/:2:2","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"Gitlab 安装 以下配置完成后，Gitlab基本配置完成，登录网站设置默认管理员密码即可登录，默认管理员帐号为 root # install gitlab cd /home/git sudo -u git -H git clone https://gitlab.com/gitlab-org/gitlab-foss.git -b 13-0-stable gitlab cd ${gitlab_path} sudo -u git -H cp config/gitlab.yml.example config/gitlab.yml sudo -u git -H editor config/gitlab.yml sudo -u git -H cp config/secrets.yml.example config/secrets.yml sudo -u git -H chmod 0600 config/secrets.yml sudo chown -R git log/ sudo chown -R git tmp/ sudo chmod -R u+rwX,go-w log/ sudo chmod -R u+rwX tmp/ sudo chmod -R u+rwX tmp/pids/ sudo chmod -R u+rwX tmp/sockets/ sudo -u git -H mkdir -p public/uploads/ sudo chmod 0700 public/uploads sudo chmod -R u+rwX builds/ sudo chmod -R u+rwX shared/artifacts/ sudo chmod -R ug+rwX shared/pages/ sudo -u git -H cp config/puma.rb.example config/puma.rb sudo -u git -H editor config/puma.rb sudo -u git -H git config --global core.autocrlf input sudo -u git -H git config --global gc.auto 0 sudo -u git -H git config --global repack.writeBitmaps true sudo -u git -H git config --global receive.advertisePushOptions true sudo -u git -H git config --global core.fsyncObjectFiles true sudo -u git -H cp config/resque.yml.example config/resque.yml sudo -u git -H editor config/resque.yml sudo -u git cp config/database.yml.postgresql config/database.yml sudo -u git -H editor config/database.yml sudo -u git -H chmod o-rwx config/database.yml # install gems sudo -u git -H bundle install --deployment --without development test mysql aws kerberos # install gitlab-shell sudo -u git -H bundle exec rake gitlab🐚install RAILS_ENV=production sudo -u git -H editor /home/git/gitlab-shell/config.yml # install gitlab-workhorse sudo -u git -H bundle exec rake \"gitlab:workhorse:install[/home/git/gitlab-workhorse]\" RAILS_ENV=production # install gitaly cd ${gitlab_path} sudo -u git -H bundle exec rake \\ \"gitlab:gitaly:install[/home/git/gitaly,/home/git/repositories]\" RAILS_ENV=production sudo chmod 0700 ${gitlab_path}/tmp/sockets/private sudo chown git ${gitlab_path}/tmp/sockets/private sudo -u git -H editor ${gitaly_path}/config.toml sudo -u git -H sh -c \\ \"${gitlab_path}/bin/daemon_with_pidfile ${gitlab_path}/tmp/pids/gitaly.pid ${gitaly_path}/gitaly ${gitaly_path}/config.toml \u003e\u003e ${gitlab_path}/log/gitaly.log 2\u003e\u00261 \u0026\" # 初始化 sudo -u git -H bundle exec rake gitlab:setup RAILS_ENV=production force=yes sudo cp lib/support/init.d/gitlab /etc/init.d/gitlab sudo cp lib/support/init.d/gitlab.default.example /etc/default/gitlab sudo update-rc.d gitlab defaults 21 sudo systemctl enable gitlab sudo cp lib/support/logrotate/gitlab /etc/logrotate.d/gitlab sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production # GetText PO files sudo -u git -H bundle exec rake gettext:compile RAILS_ENV=production # Assets sudo -u git -H yarn install --production --pure-lockfile sudo -u git -H bundle exec rake gitlab:assets:compile \\ RAILS_ENV=production NODE_ENV=production \\ NODE_OPTIONS=\"--max_old_space_size=1024\" # 内存限制在1G if [ $? != 0 ]; then echo \"compile assets error. desc '--max_old_space_size'\" return 64 fi # Nginx sudo cp lib/support/nginx/gitlab-ssl /etc/nginx/sites-available/gitlab sudo ln -sf /etc/nginx/sites-available/gitlab /etc/nginx/sites-enabled/gitlab sudo editor /etc/nginx/sites-available/gitlab sudo nginx -t; if [ $? != 0 ]; then echo \"nginx config error. editor /etc/nginx/sites-available/gitlab\" return 64 fi # end sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production sudo systemctl start gitlab 接下来安装 Gitlab Runner v13.4.1，使 CI/CD 可用 curl -LJO https://gitlab-runner-downloads.s3.amazonaws.com/latest/deb/gitlab-runner_amd64.deb dpkg -i gitlab-runner_amd64.deb sudo gitlab-runner register # 注册 runner sudo -u gitlan-runner -H mv /home/gitlab-runner/.bash_logout /home/gitlab-runner/.bash_logout.bkp sudo systemctl restart gitlab-runnner sudo systemctl enable gitlab-runner ","date":"2020-10-13","objectID":"/2020/service/:2:3","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["Apps"],"content":"GitLab 开启邮件服务 我们的GitLab使用的是源码安装，需要修改 config/gitlab.yml 开启 emil gitlab_email_from=\"noreply@example.com\" gitlab_email_reply=\"noreply@example.com\" cd /home/git/gitlab sed -i \"s/email_enabled:.*/email_enabled: true/\" config/gitlab.yml sed -ie \"s/email_from:.*/email_from: ${gitlab_email_from}\" config/gitlab.yml sed -ie \"s/email_reply_to:.*/email_reply_to: ${gitlab_email_reply}\" config/gitlab.yml cp config/initializers/smtp_settings.rb.sample config/initializers/smtp_settings.rb 将email启用后，还需要配置smtp，可以参考 官方教程，修改配置文件 config/initializers/smtp_settings.rb ，将 ActionMailer::Base.smtp_settings 修改为以下内容 enable: true, address: \"mail.example.com\", port: 465, user_name: \"noreply@example.com\", password: \"YourPassword\", domain: \"mail.example.com\", authentication: :login, enable_starttls_auto: true, tls: true, openssl_verify_mode: 'none' 开启对邮件的 S/MIME 签名服务，将你的S/MIME私钥保存到 ${gitlab\\_path}/.gitlab\\_smime\\_key=，公钥保存到 =${gitlab_path}/.gitlab_smime_cert sed -i \"103s/# enabled:.*/enabled: true/\" config/gitlab.yml 配置完成后重启服务即可，如果需要验证SMTP是否工作，可以使用以下命令 echo \"Notify.test_email('${gitlab_email_reply}', 'Message Subject', 'Message Body').deliver_now\" | \\ sudo -u git -H bundle exec rails console -e production ","date":"2020-10-13","objectID":"/2020/service/:2:4","tags":["server","Application"],"title":"在服务器上部署一些服务","uri":"/2020/service/"},{"categories":["编译原理"],"content":"GinShio | 编译原理第三章读书笔记","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"词法分析是编译器的第一阶段，主要负责读取源程序的输入字符，将它们组成 词素 ，生成并输出一个词法单元序列，每个词法单元对应一个词素，这个词法单元序列将被语法分析器进行语法分析。除此之外，词法分析器还会过滤源程序中的注释和空白，生成错误信息与源程序的位置关联起来，有时还会进行宏扩展。 学习词法分析时，需要分清以下三个相关但有区别的术语 词法单元 ：由一个词法单元名和一个可选的属性值组成，词法单元名是一个表示某种词法单位的抽象符号，比如关键字，或标识符的输入字符序列 词素 ：源程序中的字符序列，它和某一词法单元的模式匹配，并被词法分析器识别为该词法单元的一个实例 模式 ：描述了一个词法单元的词素可能具有的形式。对于关键词它是组成关键字的字符序列；对于标识符和其他词法单元，模式是一个更加复杂的结构，可以和很多符号串匹配 比如 printf(\"Total=%d\\n\"，source); 中，printf 和 source 都是和词法单元 id 的模式匹配的词素，而字符串则是一个和 literal 匹配的词素，以下表格为词法单元的示例 词法单元 非正式描述 词素示例 if 关键字，字符 i/f if else 关键字，字符 e/l/s/e else comparison 比较运算符 \u003c，\u003c= id 普通标识符 pi，D2，source number 数字常量 3.1415926，1024 literal 字符串常量 “hello world!” ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:0:0","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"词法单元的规约 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:1:0","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"串和语言 字母表 (alphabet) 是一个有限的符号集合，符号的典型示例是包括字母、数字和标点符号，常见的字母表如 ASCII 和 Unicode 。 串 (string) 是某个字母表中符号的一个有穷序列，串 s 的长度，表示 s 中符号出现的次数，记作 \\(|s|\\) ，长度为 0 的串被称为空串，记作 \\(\\varepsilon\\) 。 语言 (language) 是某个给定字母表上一个任意的可数的串的集合，此外空集 \\(\\varnothing\\) 和 仅包含空串的集合都是语言。 词法分析中，最重要的语言上的运算是 并 、 连接 和 闭包 。连接是将一个串附加到另一个串的后面形成新串，例如 \\(x=dog, y=house\\) ，那么 x、y 的连接 \\(xy=doghouse\\) ；空串是连接运算的 单位元 ，即对于任意串 \\(s\\varepsilon = \\varepsilon s = s\\) 。两个串的连接可以被看作乘积，那么可以定义串的指数运算： \\(s^0=\\varepsilon，s^i = s^{i-1}s(i \u003e 0)\\) 。Kleene 闭包 (closure)，记作 \\(L^{*}\\) ，即将 L 连接 0 次或多次后得到的串集； 正闭包 与闭包基本相同，但不包括 \\(L^0\\) ，也就是说，除非 \\(\\varepsilon\\) 属于 L，否则 \\(\\varepsilon \\notin L\\) 。 运算 定义和表示 L 和 M 的并 \\(L \\cup M = \\{s \\mid s \\in L \\ or\\ s \\in M\\}\\) L 和 M 的连接 \\(LM = \\{st \\mid s \\in L \\ and\\ t \\in M\\}\\) L 的 Kleene 闭包 \\(L^{*} = \\cup_{i=0}^{\\infty} L^i\\) L 的正闭包 \\(L^{+} = \\cup_{i=1}^{\\infty} L^i\\) 示例 令 L = {A, B, \\(\\ldots\\), Z, a, b, \\(\\ldots\\), z}，令 D = {0, 1, \\(\\ldots\\), 9}，这是两个字母表，也可以认为是两个串长都为 1 的语言，对他们进行上述 4 种运算 \\(L \\cup D\\) 是字母和数字的集合，结果是 62 个长度为 1 的串 \\(LD\\) 是包含 520 个长度为 2 的集合，每个串都是一个字母跟一个数字 \\(L^4\\) 是由四个字母构成的串的集合 \\(L^{*}\\) 是由字母构成的串的集合，包含空串 \\(\\varepsilon\\) \\(D^{+}\\) 是由一个或多个数字构成的串的集合，不包含空串 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:1:1","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"正则表达式 正则表达式由常量和运算构成，它们分别是字符串的集合和在这些集合上的运算，正则表达式可以由较小的正则表达式按照一定规则递归地构建。 归纳基础 \\(\\varepsilon\\) 是一个正则表达式， \\(L(\\varepsilon) = \\{\\varepsilon\\}\\) ，即该语言仅包含空串 如果 a 是 \\(\\Sigma\\) 上的一个符号，那么 a 是一个正则表达式，并且 \\(L(\\textbf{a}) = \\{a\\}\\) ，即该语言仅包含一个长度为 1 的字符串 a 归纳步骤 ：假定 r 和 s 都是正则表达式，分别表示语言 \\(L( r)\\) 和 \\(L(s)\\) ，那么 \\(( r)|(s)\\) 是一个正则表达式，表示语言 \\(L( r) \\cup L(s)\\) \\(( r)(s)\\) 是一个正则表达式，表示语言 \\(L( r)L(s)\\) \\(( r)^{*}\\) 是一个正则表达式，表示语言 \\((L( r))^{*}\\) \\(( r)\\) 是一个正则表达式，表示语言 \\(L( r)\\) 按照以上定义，正则表达式经常会包含一些不必要的括号，一般正则表达式有如下优先级 一元运算符 \\(*\\) 具有最高优先级，是左结合的 连接具有次高优先级，是左结合的 \\(|\\) 优先级最低，是左结合的 以下表格列出正则表达式中常用定律 定律 描述 \\(r\\mid s = s\\mid r\\) \\(\\mid\\) 满足交换律 \\(r\\mid(s \\mid t) = (r \\mid s) \\mid t\\) \\(\\mid\\) 满足结合律 \\(r(st) = (rs)t\\) 连接满足结合律 \\(r(s \\mid t) = rs \\mid rt; (s \\mid t)r = sr \\mid tr\\) 连接对 \\(\\mid\\) 满足分配率 \\(\\varepsilon r = r\\varepsilon = r\\) \\(\\varepsilon\\) 是连接的单位元 \\(r^{*} = (r\\mid\\varepsilon)^{*}\\) Kleene 闭包中一定包含 ε \\(r^{**} = r^{*}\\) \\(*\\) 具有幂等性 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:1:2","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"正则定义 如果 \\(\\Sigma\\) 是 基本符号集 ，那么一个 正则定义 (regular definition) 是具有如下形式的定义序列 \\[ \\begin{aligned} d_1 \\rightarrow r_1 \\\\ d_2 \\rightarrow r_2 \\end{aligned} \\\\ \\dots \\\\ d_n \\rightarrow r_n \\] 每个 \\(d_i\\) 都是一个新符号，它们都不在 \\(\\Sigma\\) 中，并且各不相同 每个 \\(r_i\\) 是字母表 \\(\\Sigma \\cup \\{d_1，d_2，\\ldots，d_n\\}\\) 上的正则表达式 示例 C 语言的标识符是由字母或下划线开头，字母、数字和下划线组成的串，正则定义如下 \\[ \\begin{aligned} \\textit{letter}\\_ \u0026 \\rightarrow A | B | \\ldots | Z | a | b | \\ldots | z | \\_ \\\\ \\textit{digit} \u0026 \\rightarrow 0 | 1 | \\ldots | 9 \\\\ \\textit{id} \u0026 \\rightarrow \\textit{letter\\_}(\\textit{letter\\_}|dight)^{*} \\end{aligned} \\] 在进行词法分析器的规约时，现有的正则定义太过于麻烦，于是对其做了一些扩展，当然除了以下介绍的 GNU 、 Perl 等都有互不兼容的正则表达式扩展 一个或多个实例 (+)，表示一个正则表达式及其语言的正闭包， + 与 * 具有相同的优先级与结合性 零个或一个实例 (?)，表示一个正则表达式及其语言出现零或一次， \\(r? = r|\\varepsilon\\) ，/?/ 与 * 具有相同的优先级与结合性 字符类，一个正则表达式 \\(a_1 | a_2 | \\ldots | a_n\\) 可以缩写为 \\([a_1a_2\\ldots a_n]\\) ，如果 \\(a_1\\) 到 \\(a_n\\) 是连接的序列时可以缩写为 \\([a_1-a_n]\\) 示例 C 语言的数字字面量可以分为 整型字面量 与 浮点型字面量，以下给出它们的正则定义 \\[ \\begin{aligned} \\textit{digit}\u0026\\rightarrow [0-9] \\\\ \\textit{digits}\u0026\\rightarrow digit^{+} \\\\ \\textit{number}\u0026\\rightarrow [+-](\\textit{digits}.?\\textit{digit}^{*}|.\\textit{digits})([eE][+-]?\\textit{digits})? \\end{aligned} \\] ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:1:3","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"状态转换图 将模式首先需要转换为具有特定风格的流图，我们称为 状态转化图 (transition diagram)，它有一组被称为 状态 (state) 的结点，词法分析器扫描输入串的过程中寻找和某个模式匹配的词素，状态图上的每个状态代表一个可能在过程中出现的情况，结点包含了我们在进行词法分析时需要的全部信息。状态图的 边 (edge) 从图的一个状态指向另一个状态，每条边的标号包含了一个或多个符号。例如我们现在处于状态 s 下，下一个输入的符号为 a，那么我们就会在状态图中寻找一条从 s 离开且符号为 a 的边，并进入这条边所指向的下一个状态。关于状态转移图的重要约定如下 某些状态被称为 接受状态 或 最终状态 ，在图中用双层圈表示，如果该状态要执行一个动作，通常是向语法分析器返回一个词法单元和相关属性值 如果要回退一个位置，我们一般在该状态上加一个 * ，如果要回退多个位置则需要加相应数量的 * 一个状态被称为 开始状态 或 初始状态 ，该状态由一条没有出发结点的、标号为 start 的边指明，在读入任何符号之前，状态图总是位于它的起始状态 我们用 SQL 中的关系运算符来举个例子 词素 词法单元名 属性值 \u003c relop LT \u003c= relop LE = relop EQ \u003c\u003e relop NE \u003e relop GT \u003e= relop GE 对于符号来说很简单，但对于关键字来说，它们是被保留的，但它们看起来很像标识符，因此我们常常使用两种方法来处理长的很像标识符的关键字 初始化时将各个保留字填入符号表，符号表中的某个字段会指明这些串并非普通的标识符，并指出它们所代表的词法单元 为每个保留字建立单独的状态转换图，并设立词法单元的优先级，当同时匹配关键字模式与 id 模式时优先识别保留字的词法单元 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:2:0","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"有穷自动机 一些词法分析其生成程序使用了 有穷自动机 (finite automata) 这种表示方式，其在本质上是与状态转换图类似的图，但有如下不同 有穷自动机不是识别器，它们只能对每个可能输入的串进行简单的回答是或否 分为两类 不确定有穷自动机 (Nondeterministic Finite Automata，NFA)，它们对其边上的标号没有任何限制，一个符号标记离开同一状态的多条边，并且空串也可以作为标记 确定有穷自动机 (Deterministic Finite Automata，DFA)，对于每个状态及自动机输入字母表的每个符号，有且只有一条离开的状态、以该符号为标点的边 确定与不确定的有穷自动机能识别的语言的集合是相同的，这些语言集合正好是能够用正则表达式描述的语言的集合，这个集合中的语言被称为 正则语言 (regular language)。 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:3:0","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"不确定的有穷状态机 首先，一个 NFA 由以下几部分组成 一个有穷的状态集合 \\(S\\) 一个输入符号集 \\(\\Sigma\\) ，即输入字母表，我们假设 \\(\\varepsilon \\notin \\Sigma\\) 一个 转换函数 (transition function)，它为每个状态和 \\(\\Sigma \\cup \\{\\varepsilon\\}\\) 中的每个符号都给出了相应的 后续状态 (next state) 的集合 \\(S\\) 中一个状态 \\(s_0\\) 被指定为初始状态 \\(S\\) 中一个子集 \\(F\\) 被指定为接受状态集合 我们可以将 NFA 表示为一个转换图，图中的结点是状态，带有标号的边表示自动机的转换函数，这个图与转台转换图十分相似，但还是有一些区别的 同一个符号可以标记从同一状态出发到达多个目标状态的多条边 一条边的符号不仅可以是输入字母表中的符号，也可以是空串 除了转换图，我们也可以将 NFA 表示为一张转换表，表的各行对应与状态，各列对应于输入符号和 \\(\\varepsilon\\) 。对应于一个给定状态和给定输出的条目是将 NFA 的转换函数应用于这些参数后得到的值，如果转换函数没有没有相关信息，那么我们就将 \\(\\emptyset\\) 填入相应的位置。如下表就是上图的转换表形式 状态 a b \\(\\varepsilon\\) 0 {0, 1} {0} \\(\\emptyset\\) 1 \\(\\emptyset\\) {2} \\(\\emptyset\\) 2 \\(\\emptyset\\) {3} \\(\\emptyset\\) 3 \\(\\emptyset\\) \\(\\emptyset\\) \\(\\emptyset\\) 在转换表上，我们可以很容易确定，一个给定状态和一个输入符号相对应的转换; 但是如果输入字母表很大，且大多数状态在大多数输入字符上没有转换时，转换表需要占用大量的空间 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:3:1","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"确定的有穷状态机 DFA 是 NFA 的一个特例，主要体现在 没有输入 \\(\\varepsilon\\) 之上的转换动作 对每个状态 s 和每个输入符号 a，有且只有一条标号为 a 的边离开 s NFA 抽象地表示了用来识别某个语言中的串的算法，DFA 则是一个简单具体的识别串的算法，在构造词法分析器的时候我们使用的是 DFA。 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:3:2","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"从正则表达式构造NFA 现在我们给出一个算法，将任何正则表达式转换为接受相同语言的NFA，这个算法是 语法制导 的，对于每个子表达式该算法构造一个只有一个接受状态的NFA。 McMaughton-Yamada-Thompson 算法 输入：字母表 \\(\\Sigma\\) 上的一个正则表达式 r 输出：一个接受 L(r) 的 NFA N 方法：首先对r进行语法分析，分解出组成它的子表达式。构造一个NFA的规则分为 基本规则 和 归纳规则 。基本规则处理不包含运算符的子表达式，而归纳规则根据一个给定的表达式的直接子表达式的NFA构造出这个表达式的NFA 基本规则 ：构造NFA，其中 i 是一个新状态，也是这个NFA的开始状态；f 是另一个新状态，也是这个NFA的接受状态。对于表达式 \\(\\varepsilon\\) 以及字母表 \\(\\Sigma\\) 中的子表达式 a，构造以下 NFA 归纳规则 ：假设正则表达式 s 和 t 的 NFA 分别为 N(s) 和 N(t)，表达式 r 的 NFA 为 N(r) 假设 r = s|t ，构造 N(r)，可以得到从 i 到 N(s) 或 N(t) 的开始状态各有一个 \\(\\varepsilon\\) 转换，从 N(s) 和 N(t) 的接受状态到 f 也各有一个 \\(\\varepsilon\\) 转换。因为从 i 到 f 的任何路径要么只通过 N(s)，要么只通过 N(t)，且离开 i 或进入 f 的 \\(\\varepsilon\\) 转换都不会改变路径上的标号，因此我们可以判定 N(r) 识别 \\(L(s) \\cup L(t)\\) ，即 \\(L( r)\\) 假设 r = st ，构造 N(r)，N(s) 的开始状态变为了 N(r) 的开始状态，N(t) 的接受状态变成了 N(r) 唯一接受状态，N(s) 的接受状态和 N(t) 的开始状态合并为一个状态，合并后的状态拥有原来进入和离开合并前的两个状态的全部转换。 假设 r = \\(s^{*}\\) ，构造 N(r)，i 和 f 是两个新状态，分别为 N(r) 的开始状态和唯一的接受状态。要从i到达f我们需要沿着新引入的标号为 \\(\\varepsilon\\) 的路径前进，这个路径对应 \\(L(s)^{0}\\) 中的一个串。我们也可以到达 N(s) 的开始状态，然后经过该 NFA，在零次或多次从它的接受状态回到它的开始状态并重复上述过程。 r = (s) ，那么 L(r) = L(s)，我们可以直接把 N(s) 当作 N(r)。 N(r) 接受语言 L(r) 之外，构造得到的 NFA 还具有以下性质: N(r) 的状态数最多为 r 中出现的 运算符 和 运算分量 的总数的 2倍 ，因为算法的每一个构造步骤最多只引入两个新状态 N(r) 有且只有一个开始状态和一个接受状态 N(r) 中除接受状态之外的每个状态要么有一条其标号为 \\(\\Sigma\\) 中符号的出边，要么有两条标号为 \\(\\varepsilon\\) 的出边 ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:3:3","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"NFA 到 DFA 我们需要将 NFA 转换为 DFA，一般采用 子集构造法 直接模拟 NFA。子集构造法的基本思想是让构造得到的 DFA 的每个状态对应于 NFA 的一个状态集合。DFA 的状态数有可能是 NFA 状态数的指数，不过对于真实的语言，NFA 与 DFA 的状态数量大致相同。 子集构造算法 输入：一个 NFA N 输出：一个接受同样语言的 DFA D 方法：我们为 D 构造一个转换表 Dtran 。D的每个状态是一个 NFA 的状态集，我们构造 Dtran 使得 D 并行的模拟 N 在遇到一个给定输入串时可能执行的所有动作。在读入第一个输入符号之前，N 位于 \\(\\varepsilon-closure(s_0)\\) 中的任何状态上。假定 N 在读入字符串 x 后位于集合 T 的状态上，那么下一个输入符号 a，N 可以移动到集合 \\(move(T，a)\\) 中的任何状态。 操作 描述 \\(\\scriptsize \\varepsilon-closure(s)\\) 从 NFA 的状态 s 开始只通过 \\(\\varepsilon\\) 转换到达的 NFA 状态集合 \\(\\scriptsize \\varepsilon-closure(T)\\) 从 T 中某个 NFA 状态 s 开始只通过 \\(\\varepsilon\\) 转换到达的 NFA 状态集合，即 \\(\\cup_{s \\in T} \\varepsilon-closure(s)\\) \\(move(T,a)\\) 从 T 中某个状态 s 出发通过标号 a 的转换到达的 NFA 状态的集合 简单的说，NFA 中起始状态与起始状态经过 \\(\\varepsilon\\) 转换后所到达的所有状态，这些状态所组成的集合就是转换成 DFA 的起始状态，而这个集合中的所有状态分别经过某一路径转换和转换后再经过 \\(\\varepsilon\\) 转换的状态组成了另一个 DFA 状态，以此下去构成了所有 DFA 中的所有状态 我们继续以上图 \\((a|b)^{*}abb\\) 为例进行从 NFA 到 DFA 的装换，起始状态 A 为 \\(\\varepsilon-closure(0)\\) ，即 \\(A=\\{0，1，2，4，7\\}\\) ，而输入字母表为 \\(\\{a，b\\}\\) ，那么接下来分别计算 \\(Dtran[A，a] = \\varepsilon-closure(move(A,a))\\) 以及 \\(Dtran[A，b] = \\varepsilon-closure(move(A,b))\\) 分别得到 DFA 的状态 B 与状态 C，最终依次计算，我们会得到一张 NFA 与 DFA 对应关系表 (下表)，这样就可能很轻松的完成 NFA 向 DFA 的转换 DFA 状态 NFA 状态集 经过 a 转换得到的状态 经过 b 转换得到的状态 A {0,1,2,4,7} B C B {1,2,3,4,6,7,8} B D C {1,2,4,5,6,7} B C D {1,2,4,5,6,7,9} B E E {1,2,4,5,6,7,10} B C ","date":"2020-07-16","objectID":"/2020/compilerprinciple_002/:3:4","tags":["笔记","龙书"],"title":"编译原理 (2) – 词法分析1","uri":"/2020/compilerprinciple_002/"},{"categories":["编译原理"],"content":"GinShio | 编译原理第一章读书笔记","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"编译器 编译器，是一个 程序 ，它可以阅读以某一 源语言 编写的程序，并把该程序翻译成一个 等价的 、 用 目标语言 编写的程序; 解释器，是另一种语言处理器，它直接利用用户提供的输入执行源程序中指定的操作。 编译器产生的机器语言目标程序通常比一个解释器 快 得多，但是解释器的 错误诊断效果 比编译器更好，因为解释器是逐个语句地执行源程序。 ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:1:0","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"基本组成 编译器是由 预处理器 (preprocessor)、 编译器 (compiler)、 汇编器 (assembler)、 链接器 (linker) 这几大主要部分组成，最后生成一个可执行程序 (executable)。 预处理器：主要负责文本替换或巨集展开 编译器：可能产生一个汇编语言的中间代码作为其输出，因为汇编语言比较容易 输出 和 调试 汇编器：将编译器产生的中间结果生成 可重新定位的 机器代码 链接器：将一个或多个由编译器或汇编器生成的目标文件外加库，链接为一个可执行文件 现代编译器中，基本可以分步骤调用编译器的各个部分，生成所需要的阶段输出，以 gcc 和 clang 为例 预处理 (-E)：输出文件经过预处理器生成的源代码，一般以 .i 作为文件扩展名 编译 (-S)：将源代码或预处理文件编译生成汇编代码，汇编代码后缀名 .s 汇编 (-c)：将源代码或之前步骤生成的中间代码汇编生成可重新定位的机器码，文件后缀名为 .o 链接：将源文件或之前步骤生成的中间代码链接生成可执行程序 ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:1:1","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"结构 编译器由两部分组成， 分析 部分和 综合 部分 分析：将源程序分解成为多个组成元素，并在要素之上加上语法结构。分析部分被称为编译器的 前端 综合：根据中间表示和符号表中的信息来构造用户期待的目标程序。综合部分被称为编译器的 后端 词法分析 (lexical analysis)：词法分析器读入组成源程序的字符流，并将它们组成成为有意义的 词素 (lexeme) 的序列。对于每个词素，词法分析器产生如下形式的 词法单元 (token) 作为输出 \u003ctoken-name，attribute-value\u003e 语法分析 (syntax analysis)：语法分析器使用由词法分析器生成的各个词法单元的第一个分量来创建树形的中间表示，该中间表示给出了词法分析产生的词法单元流的语法结构。常用表示方法为 语法树 (syntax tree)，树中的每个内部接点表示一个运算，而该结点的子结点表示该运算的分量 语义分析 (semantic analysis)：使用语法树和符号表中的信息来检查源程序是否和语言定义的语义一致。同时也会收集类型信息，并把这些信息存放在语法树或符号表中 中间代码生成：编译器一般在语法分析、语义分析结束之后，会生成一个明确的低级的或类机器语言的中间表示，该中间表示应该 易于生成 、且可以被 轻松翻译 为目标机器语言 代码优化：机器无关的代码优化步骤试图改进中间代码，以便生成 更好 的目标代码 代码生成：以源程序的中间表示形式作为输入，并把它映射到目标语言，代码生成必须要 合理分配寄存器 符号表管理：记录源程序中使用的变量名称，并收集和每个名字的各种属性有关的信息，这些属性一般包含 存储分配 、 类型 、 作用域 等 ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:1:2","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"构造工具 除通用软件开发工具外，编译器的实现一般需要专业的工具来实现，这些专用工具使用专用的语言来 描述 和 实现 特定的组件，这些生成器会隐藏相当复杂的生成算法细节，并生成易于与其他部分集成的组件 语法分析器的生成器：可以根据一个程序设计语言的语法描述自动生成语法分析器 扫描器的生成器：可以根据一个语言的语法单元的正则表达式描述生成词法分析器 语法执导的翻译引擎：可以生成一组用于遍历分析树并生成中间代码的程序 代码生成器的生成器：根据一组关于如何把中间语言的每个运算翻译成为目标机上的机器语言的规则，生成一个代码生成器 数据流分析引擎：可以帮助收集数据流信息，即程序中的值如何从程序的一部分传递到另一部分，这是代码优化的重要部分 编译器构造工具集：用于构造编译器不同阶段的例程的完整集合 ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:1:3","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"程序设计语言 20 世纪 40 年代，第一台计算机问世，它使用 01 序列组成的机器语言编程，直到现在计算机的最底层依然以这种方式运行。但这种编程速度 慢 且 枯燥 ， 容易出错 ，写出的程序 难以 修改与理解。 20 世纪 50 年代早期，人们开始对助记汇编语言开发，汇编语言已开始仅是对机器语言的助记表示，后来加入了 宏指令 ，可以为频繁使用的机器指令序列定义带有参数的缩写。 之后，程序设计语言从汇编语言开始走向高级语言，用于科学计算的 Fortran 、 用于商业数据处理的 Cobol 、 用于符号计算的 Lisp 等等，随着时间的推移，越来越多带着新特性的高级语言被开发出来，它们更加 简单 、 自然 、 强大 。 根据时间与应用关系，龙书将程序设计语言分为了 5 代 第一代：机器语言 第二代：汇编语言 第三代：高级程序设计语言，例如 Fortran、C、C++、Java 等 第四代：为特定应用设计的语言，例如用于数据库查询的 SQL，用于文字排版的 Postscript 第五代：基于逻辑和约束的语言，例如 Prolog 和 OPS5 根据程序编程范式的不同，分为 2 种 强制式 (imperative)：又称 命令式 ，程序指明如何完成一个计算任务，所有强制式语言都有表示 程序状态 和 语句 的表示方法，语句可以改变程序状态，例如 C、C++等 声明式 (declarative)：程序指明需要进行哪些运算，例如 函数式程序设计语言 和 Prolog 等 ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:2:0","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"环境与状态 标识符 (identifier) 是一个字符串，它通常由子母、数字和下划线组成，它被用来标记一个 实体 ，例如 数据对象 、 过程 、 类型 等。变量指向存储中的某一个特定位置，同一个标识符可能被多次声明 (例如在递归过程中的局部变量)，每一个这样的声明都会引入一个新的变量。所有的标识符都是名字，不过名字不一定是标识符，比如 x.y 这样的名字被称为 受限名字 (qualified name)，表示变量 x 所指向结构中的字段 y。 名字和内存 (存储) 位置的关联，以及之后和值的关联可以用两个映射来描述，这两个映射随着程序的运行而改变。 环境 (environment) 是从一个名字到存储位置的映射，例如 C 语言中的右值； 状态 (state) 是一个内存位置到它们值的映射，例如 C 语言中左值所对应的右值 大多数环境和状态是 动态绑定 的，一般全局变量的环境映射是静态的，编译器可以在生成目标代码的时候为其分配一个地址；常量的声明一般其状态是静态绑定的，我们看到这个语句时就能确定绑定关系，并且在程序的运行时这个绑定不能改变。 ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:2:1","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"静态与动态 允许编译器静态决定某个问题时，或者说这个问题可以在 编译时 (compile time) 决定，我们称这个语言使用了 静态策略 (static policy)。一个问题只允许在 运行时 (run time) 做出决定，那么称之为 动态策略 (dynamic policy)。比如 C++中的模板计算就是静态策略，而多继承中的多态则是动态策略。 作用域 (scope) 也需要关注静态还是动态，如果仅通过阅读程序即可确定一个声明的作用域，即在编译时就可确定其作用域，那么这个语言使用 静态作用域 ，或者说是 词法作用域 (lexical scope)。否则，这个语言使用 动态作用域 ，如果使用动态作用域，在程序运行时，同一个对 x 的使用会指向 x 的几个声明之一。或者简单的说，静态作用域关注在 何处定义 ，动态作用域关注 何处声明 或 何处调用 a=1; function foo() { echo $a; # 静态作用域输出1，动态作用域输出2 } function bar() { a=2; foo; } bar; ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:2:2","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":["编译原理"],"content":"参数的传递机制 值调用 (call-by-value)，在调用过程中会对实参进行求值或拷贝，被调用过程中所有有关形式参数的计算被局限于这一过程中，实参本身不会被影响 引用调用 (call-by-reference)，在调用过程中，以实参的地址作为形参的值传递给被调用者，在使用时就会直接使用这个内存地址，因此形参被修改会影响到实参本身 ","date":"2020-07-14","objectID":"/2020/compilerprinciple_001/:2:3","tags":["笔记","龙书"],"title":"编译原理 (1) – 编译器与程序设计语言","uri":"/2020/compilerprinciple_001/"},{"categories":null,"content":"友情连接 我的博客信息 名称： GinShio 简介： VENI VIDI VICI 地址： https://blog.ginshio.org/ 头像： https://blog.ginshio.org/avatar.png ","date":"0001-01-01","objectID":"/links/:0:0","tags":null,"title":"友人帐","uri":"/links/"}]